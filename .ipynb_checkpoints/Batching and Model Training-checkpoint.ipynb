{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification\n",
    "\n",
    "## Batching and Model Training\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Loading data\n",
    "import numpy as np\n",
    "import warnings \n",
    "import re # text matching\n",
    "from collections import Counter # for vocabulary\n",
    "from sklearn.model_selection import train_test_split # train test splits\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Processing\n",
    "\n",
    "We will first do all the necessary pre-processing before starting to create batches and training the model. All the steps are explained in the notebook named `Text Cleaning.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "# Drop unnecesary columns and duplicates\n",
    "new_data = data.drop_duplicates(subset=['UserId', 'ProfileName', 'Time', 'Text'])\n",
    "# Get useful columns\n",
    "useful_data = new_data[['Text', 'Score']]\n",
    "# Calculate length of each sentence without tokenizer\n",
    "useful_data['sudo_length'] = useful_data.Text.str.split().str.len()\n",
    "# Filter examples by length\n",
    "useful_data = useful_data[(useful_data.sudo_length > 20) & (useful_data.sudo_length < 100)]\n",
    "# Remove length column\n",
    "useful_data = useful_data.drop(['sudo_length'], axis = 1)\n",
    "# print 5 rows\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Creating vocabulary\n",
    "Now its time to tokenize and create our vocabulary. We use the `TextProcessor` class on data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.vocab_dict = dict({\"<unk>\" : 0, \"<pad>\" : 1})\n",
    "        self.counter = Counter()\n",
    "\n",
    "    def tokenize(self, sent):\n",
    "        if sent.endswith(\".\"):\n",
    "            sent = sent[:-1]\n",
    "        new_x = re.sub('<.*?>', ' ', sent)\n",
    "        new_x = re.sub('\\s\\s+',' ', new_x)\n",
    "        new_x = re.sub('\\W\\s', ' ', new_x)\n",
    "        new_x = re.sub('\\w\\W{2,}', ' ', new_x)\n",
    "        new_x = new_x.lower().split()\n",
    "        return new_x\n",
    "        \n",
    "    def processDataset(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        token_set = set(tokens)\n",
    "        self.counter.update(Counter(tokens))\n",
    "        return len(tokens)\n",
    "        \n",
    "    def build_vocab(self, num_most_common_to_use=10000):\n",
    "        words = self.counter.most_common(num_most_common_to_use)\n",
    "        for i in range(num_most_common_to_use - 2):\n",
    "            self.vocab_dict[words[i][0]] = len(self.vocab_dict)\n",
    "            \n",
    "    def tokenize_and_return_length(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        return len(tokens)\n",
    "            \n",
    "    def process(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        processed = []\n",
    "        for val in tokens:\n",
    "            processed.append(self.vocab_dict.get(val, self.vocab_dict[\"<unk>\"]))\n",
    "            \n",
    "        return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(useful_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run text processor to create vocabulary. Also create a new column denoting length of tokens for corresponding review. This will be used in creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213836</th>\n",
       "      <td>I like both this version and the original with...</td>\n",
       "      <td>4</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298955</th>\n",
       "      <td>Found this product at Natural Grocers by Vitam...</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90356</th>\n",
       "      <td>These bars are an excellent choice if you're t...</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390251</th>\n",
       "      <td>I really like Kellog's Rice Krispies, but not ...</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163469</th>\n",
       "      <td>We've been using these for years for dog train...</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "213836  I like both this version and the original with...      4      54\n",
       "298955  Found this product at Natural Grocers by Vitam...      5      76\n",
       "90356   These bars are an excellent choice if you're t...      5      32\n",
       "390251  I really like Kellog's Rice Krispies, but not ...      5      86\n",
       "163469  We've been using these for years for dog train...      5      50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textprocessor = TextProcessor()\n",
    "train['length'] = train.Text.apply(textprocessor.processDataset)\n",
    "textprocessor.build_vocab(40000)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8726</th>\n",
       "      <td>You get a consistent cup of coffee with a hint...</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19322</th>\n",
       "      <td>The product arrived when predicted. The coffee...</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167856</th>\n",
       "      <td>Since I haven't seen many new reviews, I decid...</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48490</th>\n",
       "      <td>From the second I opened the packaging, I knew...</td>\n",
       "      <td>4</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541937</th>\n",
       "      <td>These are chunks more than cubes, but I like t...</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "8726    You get a consistent cup of coffee with a hint...      5      30\n",
       "19322   The product arrived when predicted. The coffee...      4      24\n",
       "167856  Since I haven't seen many new reviews, I decid...      4      68\n",
       "48490   From the second I opened the packaging, I knew...      4      69\n",
       "541937  These are chunks more than cubes, but I like t...      4      35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['length'] = test.Text.apply(textprocessor.tokenize_and_return_length)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching and Data Loader creation\n",
    "We are going to use `PyTorch` for training an `LSTM Model` for classification of reviews. Before creating the model, we first need to create dataloader, so that we can conviniently pass our training and testing examples to our model.\n",
    "\n",
    "First we will create a *Custom PyTorch* dataset class which will preprocess our examples and convert them into a set of indices corresponging to vocabulary we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.data = df\n",
    "        self.data = self.data.sort_values(by='length')\n",
    "        self.tprocess = processor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row.Text\n",
    "        label = row.Score\n",
    "        \n",
    "        text = self.tprocess.process(text)\n",
    "        \n",
    "        return (text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe that our dataset class sorted our dataframe by the length of each sentence. This allows us to create a batch with minmum padding, as we will see later when creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data : \n",
      "([66, 0, 84, 16983], 5)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ReviewDataset(train, textprocessor)\n",
    "test_dataset = ReviewDataset(test, textprocessor)\n",
    "\n",
    "print(\"Sample Data : \")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataloader\n",
    "\n",
    "#### Import Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom batch formation class\n",
    "Since our dataset contains all the examples in sorted fashion, the batch we will get from our dataloader will have the largest length sentence at the end of the batch list. In the batch collator class, we will first create an array or size `(batch_size, seq_len)`, where seq_len will be equal to the length of last sentence recieved in batch.\n",
    "\n",
    "As all the examples are sorted, padding required within a batch will be minimum as nearly equal length examples will be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    def __init__(self, pad_token = 1):\n",
    "        self.pad = pad_token\n",
    "    def __call__(self, batch):\n",
    "        batch_size = len(batch)\n",
    "        seq_len = len(batch[-1][0])\n",
    "        formed = np.zeros((batch_size, seq_len), dtype = np.long) + self.pad\n",
    "        labels = []\n",
    "        for i in range(batch_size):\n",
    "            example = batch[i]\n",
    "            formed[i, :len(example[0])] = example[0]\n",
    "            labels.append(example[1])\n",
    "            \n",
    "        return torch.LongTensor(formed), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "collator = MyCollator()\n",
    "dloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples : \n",
      "tensor([[   66,     0,    84,  ...,     1,     1,     1],\n",
      "        [  381,    56,   205,  ...,     1,     1,     1],\n",
      "        [    0,   111,   373,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [ 1562,    53,    16,  ...,     4,   671,   417],\n",
      "        [11360,  5643,   476,  ...,    14,    17,  1334],\n",
      "        [ 2343,    84,   210,  ...,   595,    20, 14153]])\n",
      "Labels : \n",
      "tensor([5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 1, 5, 5, 1, 5, 4, 5, 1, 5, 3, 5, 5, 5,\n",
      "        2, 4, 5, 1, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 4, 5, 1, 4,\n",
      "        5, 5, 5, 5, 5, 5, 3, 4, 5, 5, 5, 5, 1, 5, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dloader))\n",
    "print(\"Examples : \")\n",
    "print(batch[0])\n",
    "print(\"Labels : \")\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating calss weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 : 2.16810\n",
      "Class 2 : 4.01654\n",
      "Class 3 : 2.96066\n",
      "Class 4 : 1.54300\n",
      "Class 5 : 0.30267\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', sorted(train.Score.unique()), train.Score)\n",
    "for cat in sorted(train.Score.unique()):\n",
    "    print(\"Class {} : {:.5f}\".format(cat, weights[cat - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start creating our model for Classification!!\n",
    "\n",
    "### Import Pytorch and other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Base Model\n",
    "The base model is the simplest model we train. It consist of \n",
    "- **Embedding layer** : this layer transforms our indexes to 300-D vector that respresent a word.\n",
    "- **LSTM cell** : the core of our model, the LSTM cell\n",
    "- **Linear layer** : we take the last output of the lstm layer and use it to predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = nn.LSTM(embedding_dim, hidden_size, batch_first = True, dropout = 0.5)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hstate = None):\n",
    "        if hstate is None:\n",
    "            hstate = self.init_hidden(self.hidden_size, x.shape[0])\n",
    "            \n",
    "        cell_out, _ = self.cell(self.embedding(x), hstate)\n",
    "        \n",
    "        out = self.linear(cell_out[:, -1, :])\n",
    "        \n",
    "        return self.soft(out)\n",
    "            \n",
    "    def init_hidden(self, hidden_size, bs):\n",
    "        return (torch.zeros(1, bs, hidden_size, device=device), torch.zeros(1, bs, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating evalutaion metrics\n",
    "The evaluation metrics for classification used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetrics:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = list(range(num_classes))\n",
    "        self.epsilon = 1e-12\n",
    "        self.cmatrix = np.zeros((num_classes, num_classes), dtype = np.int64) + self.epsilon\n",
    "        \n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        \n",
    "    def update(self, pred, truth):\n",
    "        pred = pred.cpu()\n",
    "        truth = truth.cpu()\n",
    "        \n",
    "        _, idx = pred.topk(1)\n",
    "        truth = truth.view(-1, 1)\n",
    "        \n",
    "        self.total_examples += len(truth)\n",
    "        self.total_correct += sum(idx == truth).item()\n",
    "        \n",
    "        val = confusion_matrix(truth, idx, labels=self.classes)\n",
    "        \n",
    "        self.cmatrix = self.cmatrix + val\n",
    "        \n",
    "        \n",
    "    def precision_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[:, i]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def recall_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[i, :]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def scores(self, return_type = 'f1'):\n",
    "        pscores = self.precision_score()\n",
    "        rscores = self.recall_score()\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            if(pscores[i] == 0 and rscores[i] == 0):\n",
    "                scores[i] = 0\n",
    "            else:\n",
    "                scores[i] = 2 * ((pscores[i] * rscores[i]) / (pscores[i] + rscores[i])  + self.epsilon)\n",
    "            \n",
    "        if return_type == 'f1':\n",
    "            return scores\n",
    "        elif return_type == 'all':\n",
    "            all_scores = list(zip(pscores.values(), rscores.values(), scores.values()))\n",
    "            t = {}\n",
    "            for i in range(self.num_classes):\n",
    "                t[i] = all_scores[i]\n",
    "                \n",
    "            return t\n",
    "        else:\n",
    "            raise Exception(\"Invalid argument for return type\")\n",
    "            \n",
    "    def accuracy_score(self):\n",
    "        return self.total_correct / self.total_examples\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        self.cmatrix = np.zeros((self.num_classes, self.num_classes))\n",
    "            \n",
    "    def print_report(self):\n",
    "        all_scores = self.scores('all')\n",
    "        print(\"{:^15}\\t{:^15}\\t{:^15}\\t{:^15}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-score\"))\n",
    "        for c, values in all_scores.items():\n",
    "            print(\"{:^15}\\t{:^15.3f}\\t{:^15.3f}\\t{:^15.3f}\".format(c, values[0], values[1], values[2]))\n",
    "            \n",
    "        print(\"Accuracy : {:.5f} %\".format(self.accuracy_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating necessary variables along with our BaseModel, loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel(\n",
      "  (embedding): Embedding(40000, 20)\n",
      "  (cell): LSTM(20, 30, batch_first=True, dropout=0.5)\n",
      "  (linear): Linear(in_features=30, out_features=5, bias=True)\n",
      "  (soft): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(textprocessor.vocab_dict)\n",
    "HIDDEN_SIZE = 30\n",
    "EMB_DIM = 20\n",
    "NUM_CLASSES = 5\n",
    "device = 'cuda'\n",
    "\n",
    "net = BaseModel(VOCAB_SIZE, EMB_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
    "net = net.cuda()\n",
    "print(net)\n",
    "\n",
    "metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "test_metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).to(device))\n",
    "optim = opt.Adam(net.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:05<00:00, 27.94it/s]\n",
      "  0%|▎                                                                                 | 4/877 [00:00<00:23, 37.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 1 Loss : 1.60462\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     0.625     \t     1.000     \t     0.769     \n",
      "Accuracy : 0.62500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:24<00:00, 36.31it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:08, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 1 Loss : 1.59144\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     0.727     \t     1.000     \t     0.842     \n",
      "Accuracy : 0.72727 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████▍                                                           | 860/3506 [00:28<01:28, 29.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-cd5708385d45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-f7a7e5dda326>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "\n",
    "pltloss = []\n",
    "pltacc = []\n",
    "\n",
    "pltloss_test = []\n",
    "pltacc_test = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    print(\"Training Loop\")\n",
    "    for batch in tqdm(dloader):\n",
    "        metrics.reset()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        X, labels = batch[0].to(device), (batch[1] - 1).to(device)\n",
    "        pred = net(X)\n",
    "        loss = criterion(pred, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Training Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(losses) / len(losses)))\n",
    "    metrics.print_report()\n",
    "    pltloss.append(sum(losses) / len(losses))\n",
    "    pltacc.append(metrics.accuracy_score() * 100)\n",
    "    \n",
    "    test_losses = []\n",
    "    net.eval()\n",
    "    print(\"Validation Loop\")\n",
    "    for batch in tqdm(test_loader):\n",
    "        test_metrics.reset()\n",
    "\n",
    "        X, labels = batch[0].to(device), (batch[1] - 1).to(device)\n",
    "        pred = net(X)\n",
    "        loss = criterion(pred, labels)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "        test_metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Training Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(test_losses) / len(test_losses)))\n",
    "    test_metrics.print_report()\n",
    "    pltloss_test.append(sum(test_losses) / len(test_losses))\n",
    "    pltacc_test.append(test_metrics.accuracy_score() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(pltloss))), pltloss)\n",
    "plt.plot(list(range(len(pltloss_test))), pltloss_test)\n",
    "\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting Accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(pltacc))), pltacc, )\n",
    "plt.plot(list(range(len(pltacc_test))), pltacc_test)\n",
    "\n",
    "plt.title(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python38164bittorchenvconda44d23debcd2b40f9b9e35123d075dc93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
