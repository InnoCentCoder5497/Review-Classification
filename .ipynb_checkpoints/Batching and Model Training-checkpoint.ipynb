{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification\n",
    "\n",
    "## Batching and Model Training\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Loading data\n",
    "import numpy as np\n",
    "import warnings \n",
    "import re # text matching\n",
    "from collections import Counter # for vocabulary\n",
    "from sklearn.model_selection import train_test_split # train test splits\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Processing\n",
    "\n",
    "We will first do all the necessary pre-processing before starting to create batches and training the model. All the steps are explained in the notebook named `Text Cleaning.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "# Drop unnecesary columns and duplicates\n",
    "new_data = data.drop_duplicates(subset=['UserId', 'ProfileName', 'Time', 'Text'])\n",
    "# Get useful columns\n",
    "useful_data = new_data[['Text', 'Score']]\n",
    "# Calculate length of each sentence without tokenizer\n",
    "useful_data['sudo_length'] = useful_data.Text.str.split().str.len()\n",
    "# Filter examples by length\n",
    "useful_data = useful_data[(useful_data.sudo_length > 20) & (useful_data.sudo_length < 100)]\n",
    "# Remove length column\n",
    "useful_data = useful_data.drop(['sudo_length'], axis = 1)\n",
    "# print 5 rows\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Creating vocabulary\n",
    "Now its time to tokenize and create our vocabulary. We use the `TextProcessor` class on data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.vocab_dict = dict({\"<unk>\" : 0, \"<pad>\" : 1})\n",
    "        self.counter = Counter()\n",
    "\n",
    "    def tokenize(self, sent):\n",
    "        if sent.endswith(\".\"):\n",
    "            sent = sent[:-1]\n",
    "        new_x = re.sub('<.*?>', ' ', sent)\n",
    "        new_x = re.sub('\\s\\s+',' ', new_x)\n",
    "        new_x = re.sub('\\W\\s', ' ', new_x)\n",
    "        new_x = re.sub('\\w\\W{2,}', ' ', new_x)\n",
    "        new_x = new_x.lower().split()\n",
    "        return new_x\n",
    "        \n",
    "    def processDataset(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        token_set = set(tokens)\n",
    "        self.counter.update(Counter(tokens))\n",
    "        return len(tokens)\n",
    "        \n",
    "    def build_vocab(self, num_most_common_to_use=10000):\n",
    "        words = self.counter.most_common(num_most_common_to_use)\n",
    "        for i in range(num_most_common_to_use - 2):\n",
    "            self.vocab_dict[words[i][0]] = len(self.vocab_dict)\n",
    "            \n",
    "    def tokenize_and_return_length(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        return len(tokens)\n",
    "            \n",
    "    def process(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        processed = []\n",
    "        for val in tokens:\n",
    "            processed.append(self.vocab_dict.get(val, self.vocab_dict[\"<unk>\"]))\n",
    "            \n",
    "        return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(useful_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run text processor to create vocabulary. Also create a new column denoting length of tokens for corresponding review. This will be used in creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>393295</th>\n",
       "      <td>I FOUND THIS CAPPUCCINO 2 YEARS AGO.  IT HAS B...</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190413</th>\n",
       "      <td>I have a difficult time finding BLUE products ...</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247534</th>\n",
       "      <td>These are the best and most flavorful gummy be...</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399455</th>\n",
       "      <td>This food is great for dogs.  The price isnt b...</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261983</th>\n",
       "      <td>I read about these in Oprah magazine. I love t...</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "393295  I FOUND THIS CAPPUCCINO 2 YEARS AGO.  IT HAS B...      5      37\n",
       "190413  I have a difficult time finding BLUE products ...      1      83\n",
       "247534  These are the best and most flavorful gummy be...      5      60\n",
       "399455  This food is great for dogs.  The price isnt b...      5      23\n",
       "261983  I read about these in Oprah magazine. I love t...      5      53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textprocessor = TextProcessor()\n",
    "train['length'] = train.Text.apply(textprocessor.processDataset)\n",
    "textprocessor.build_vocab(40000)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>407564</th>\n",
       "      <td>the packaging and quantity is excellent, howev...</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407822</th>\n",
       "      <td>Living in a rural area, with one grocery chain...</td>\n",
       "      <td>5</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118205</th>\n",
       "      <td>Hi,&lt;br /&gt;&lt;br /&gt;I opened and tried to serve at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308368</th>\n",
       "      <td>Great taste! For years I bought another lemon ...</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165157</th>\n",
       "      <td>These beans are a bit pricey, but very few bad...</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "407564  the packaging and quantity is excellent, howev...      2      39\n",
       "407822  Living in a rural area, with one grocery chain...      5      72\n",
       "118205  Hi,<br /><br />I opened and tried to serve at ...      1      39\n",
       "308368  Great taste! For years I bought another lemon ...      5      46\n",
       "165157  These beans are a bit pricey, but very few bad...      5      40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['length'] = test.Text.apply(textprocessor.tokenize_and_return_length)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching and Data Loader creation\n",
    "We are going to use `PyTorch` for training an `LSTM Model` for classification of reviews. Before creating the model, we first need to create dataloader, so that we can conviniently pass our training and testing examples to our model.\n",
    "\n",
    "First we will create a *Custom PyTorch* dataset class which will preprocess our examples and convert them into a set of indices corresponging to vocabulary we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.data = df\n",
    "        self.data = self.data.sort_values(by='length')\n",
    "        self.tprocess = processor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row.Text\n",
    "        label = row.Score\n",
    "        \n",
    "        text = self.tprocess.process(text)\n",
    "        \n",
    "        return (text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe that our dataset class sorted our dataframe by the length of each sentence. This allows us to create a batch with minmum padding, as we will see later when creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data : \n",
      "([464, 794, 29, 4, 228, 91, 1927], 5)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ReviewDataset(train, textprocessor)\n",
    "test_dataset = ReviewDataset(test, textprocessor)\n",
    "\n",
    "print(\"Sample Data : \")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataloader\n",
    "\n",
    "#### Import Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom batch formation class\n",
    "Since our dataset contains all the examples in sorted fashion, the batch we will get from our dataloader will have the largest length sentence at the end of the batch list. In the batch collator class, we will first create an array or size `(batch_size, seq_len)`, where seq_len will be equal to the length of last sentence recieved in batch.\n",
    "\n",
    "As all the examples are sorted, padding required within a batch will be minimum as nearly equal length examples will be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    def __init__(self, pad_token = 1):\n",
    "        self.pad = pad_token\n",
    "    def __call__(self, batch):\n",
    "        batch_size = len(batch)\n",
    "        seq_len = len(batch[-1][0])\n",
    "        formed = np.zeros((batch_size, seq_len), dtype = np.long) + self.pad\n",
    "        labels = []\n",
    "        for i in range(batch_size):\n",
    "            example = batch[i]\n",
    "            formed[i, :len(example[0])] = example[0]\n",
    "            labels.append(example[1])\n",
    "            \n",
    "        return torch.LongTensor(formed), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "collator = MyCollator()\n",
    "dloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples : \n",
      "tensor([[  464,   794,    29,  ...,     1,     1,     1],\n",
      "        [    0,   111,   373,  ...,     1,     1,     1],\n",
      "        [    0,   265,   244,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    3,    74,    57,  ...,     5,    28,    32],\n",
      "        [   13,  2354,   121,  ...,     7, 16183,   640],\n",
      "        [ 3228, 33527,    96,  ...,   295,   127,  2506]])\n",
      "Labels : \n",
      "tensor([5, 5, 5, 5, 5, 5, 5, 1, 3, 5, 5, 1, 1, 5, 5, 5, 5, 4, 5, 5, 3, 1, 5, 5,\n",
      "        5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 1, 5, 4,\n",
      "        2, 5, 5, 1, 5, 5, 5, 5, 5, 5, 1, 5, 5, 4, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dloader))\n",
    "print(\"Examples : \")\n",
    "print(batch[0])\n",
    "print(\"Labels : \")\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating calss weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 : 2.16006\n",
      "Class 2 : 3.99047\n",
      "Class 3 : 2.95462\n",
      "Class 4 : 1.54268\n",
      "Class 5 : 0.30305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', sorted(train.Score.unique()), train.Score)\n",
    "for cat in sorted(train.Score.unique()):\n",
    "    print(\"Class {} : {:.5f}\".format(cat, weights[cat - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start creating our model for Classification!!\n",
    "\n",
    "### Import Pytorch and other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23900860650>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Base Model\n",
    "The base model is the simplest model we train. It consist of \n",
    "- **Embedding layer** : this layer transforms our indexes to 300-D vector that respresent a word.\n",
    "- **LSTM cell** : the core of our model, the LSTM cell\n",
    "- **Linear layer** : we take the last output of the lstm layer and use it to predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = nn.LSTM(embedding_dim, hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hstate = None):\n",
    "        if hstate is None:\n",
    "            hstate = self.init_hidden(self.hidden_size, x.shape[0])\n",
    "            \n",
    "        cell_out, _ = self.cell(self.embedding(x), hstate)\n",
    "        \n",
    "        out = self.linear(cell_out[:, -1, :])\n",
    "        \n",
    "        return self.soft(out)\n",
    "            \n",
    "    def init_hidden(self, hidden_size, bs):\n",
    "        return (torch.zeros(1, bs, hidden_size, device=device), torch.zeros(1, bs, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating evalutaion metrics\n",
    "The evaluation metrics for classification used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetrics:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = list(range(num_classes))\n",
    "        self.epsilon = 1e-12\n",
    "        self.cmatrix = np.zeros((num_classes, num_classes), dtype = np.int64) + self.epsilon\n",
    "        \n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        \n",
    "    def update(self, pred, truth):\n",
    "        pred = pred.cpu()\n",
    "        truth = truth.cpu()\n",
    "        \n",
    "        _, idx = pred.topk(1)\n",
    "        truth = truth.view(-1, 1)\n",
    "        \n",
    "        self.total_examples += len(truth)\n",
    "        self.total_correct += sum(idx == truth).item()\n",
    "        \n",
    "        val = confusion_matrix(truth, idx, labels=self.classes)\n",
    "        \n",
    "        self.cmatrix = self.cmatrix + val\n",
    "        \n",
    "        \n",
    "    def precision_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[:, i]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def recall_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[i, :]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def scores(self, return_type = 'f1'):\n",
    "        pscores = self.precision_score()\n",
    "        rscores = self.recall_score()\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            if(pscores[i] == 0 and rscores[i] == 0):\n",
    "                scores[i] = 0\n",
    "            else:\n",
    "                scores[i] = 2 * ((pscores[i] * rscores[i]) / (pscores[i] + rscores[i])  + self.epsilon)\n",
    "            \n",
    "        if return_type == 'f1':\n",
    "            return scores\n",
    "        elif return_type == 'all':\n",
    "            all_scores = list(zip(pscores.values(), rscores.values(), scores.values()))\n",
    "            t = {}\n",
    "            for i in range(self.num_classes):\n",
    "                t[i] = all_scores[i]\n",
    "                \n",
    "            return t\n",
    "        else:\n",
    "            raise Exception(\"Invalid argument for return type\")\n",
    "            \n",
    "    def accuracy_score(self):\n",
    "        return self.total_correct / self.total_examples\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        self.cmatrix = np.zeros((self.num_classes, self.num_classes))\n",
    "            \n",
    "    def print_report(self):\n",
    "        all_scores = self.scores('all')\n",
    "        print(\"{:^15}\\t{:^15}\\t{:^15}\\t{:^15}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-score\"))\n",
    "        for c, values in all_scores.items():\n",
    "            print(\"{:^15}\\t{:^15.3f}\\t{:^15.3f}\\t{:^15.3f}\".format(c, values[0], values[1], values[2]))\n",
    "            \n",
    "        print(\"Accuracy : {:.5f} %\".format(self.accuracy_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating necessary variables along with our BaseModel, loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel(\n",
      "  (embedding): Embedding(40000, 200)\n",
      "  (cell): LSTM(200, 128, batch_first=True)\n",
      "  (linear): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (soft): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(textprocessor.vocab_dict)\n",
    "HIDDEN_SIZE = 128\n",
    "EMB_DIM = 200\n",
    "NUM_CLASSES = 5\n",
    "device = 'cuda'\n",
    "\n",
    "net = BaseModel(VOCAB_SIZE, EMB_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
    "net = net.cuda()\n",
    "print(net)\n",
    "\n",
    "metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "test_metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).to(device))\n",
    "optim = opt.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/3506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:25<00:00, 24.02it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:19, 44.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 1 Loss : 1.45157\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.182     \t     1.000     \t     0.308     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.333     \t     0.500     \t     0.400     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.412     \t     0.583     \n",
      "Accuracy : 0.41667 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:23<00:00, 37.52it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:08, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 1 Loss : 1.40535\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.500     \t     1.000     \t     0.667     \n",
      "       1       \t     0.143     \t     1.000     \t     0.250     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.667     \t     0.500     \t     0.571     \n",
      "       4       \t     1.000     \t     0.357     \t     0.526     \n",
      "Accuracy : 0.40909 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:29<00:00, 23.45it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:18, 46.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 2 Loss : 1.37131\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.333     \t     0.500     \t     0.400     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     1.000     \t     1.000     \t     1.000     \n",
      "       4       \t     0.941     \t     0.941     \t     0.941     \n",
      "Accuracy : 0.75000 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 39.48it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:13, 26.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 2 Loss : 1.37724\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.143     \t     1.000     \t     0.250     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.333     \t     0.500     \t     0.400     \n",
      "       4       \t     1.000     \t     0.500     \t     0.667     \n",
      "Accuracy : 0.45455 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:26<00:00, 23.95it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:18, 46.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 3 Loss : 1.32696\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.500     \t     0.500     \t     0.500     \n",
      "       1       \t     0.250     \t     0.500     \t     0.333     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.941     \t     0.970     \n",
      "Accuracy : 0.75000 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 39.32it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:08, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 3 Loss : 1.37248\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.200     \t     1.000     \t     0.333     \n",
      "       2       \t     0.250     \t     0.500     \t     0.333     \n",
      "       3       \t     0.400     \t     0.500     \t     0.444     \n",
      "       4       \t     1.000     \t     0.571     \t     0.727     \n",
      "Accuracy : 0.54545 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:26<00:00, 23.91it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:19, 44.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 4 Loss : 1.28964\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.200     \t     0.500     \t     0.286     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     0.900     \t     0.529     \t     0.667     \n",
      "Accuracy : 0.41667 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 39.35it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:08, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 4 Loss : 1.40303\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.167     \t     0.500     \t     0.250     \n",
      "       3       \t     0.333     \t     0.750     \t     0.462     \n",
      "       4       \t     1.000     \t     0.357     \t     0.526     \n",
      "Accuracy : 0.40909 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:30<00:00, 23.29it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:18, 48.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 5 Loss : 1.25620\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.500     \t     0.667     \n",
      "       1       \t     0.200     \t     0.500     \t     0.286     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     0.937     \t     0.882     \t     0.909     \n",
      "Accuracy : 0.70833 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 38.16it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:10, 26.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 5 Loss : 1.37309\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.500     \t     1.000     \t     0.667     \n",
      "       2       \t     0.143     \t     0.500     \t     0.222     \n",
      "       3       \t     0.400     \t     0.500     \t     0.444     \n",
      "       4       \t     1.000     \t     0.500     \t     0.667     \n",
      "Accuracy : 0.50000 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:25<00:00, 24.08it/s]\n",
      "  1%|▌                                                                                 | 6/877 [00:00<00:17, 50.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 6 Loss : 1.22639\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.333     \t     0.500     \t     0.400     \n",
      "       1       \t     0.200     \t     0.500     \t     0.286     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.765     \t     0.867     \n",
      "Accuracy : 0.62500 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 39.36it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:16, 25.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 6 Loss : 1.36769\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     1.000     \t     1.000     \n",
      "       1       \t     0.333     \t     1.000     \t     0.500     \n",
      "       2       \t     0.400     \t     1.000     \t     0.571     \n",
      "       3       \t     0.333     \t     0.500     \t     0.400     \n",
      "       4       \t     1.000     \t     0.500     \t     0.667     \n",
      "Accuracy : 0.59091 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:28<00:00, 23.59it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:20, 42.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 7 Loss : 1.20487\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.667     \t     1.000     \t     0.800     \n",
      "       1       \t     0.182     \t     1.000     \t     0.308     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.471     \t     0.640     \n",
      "Accuracy : 0.50000 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 39.43it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:12, 26.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 7 Loss : 1.37487\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.167     \t     1.000     \t     0.286     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.375     \t     0.750     \t     0.500     \n",
      "       4       \t     1.000     \t     0.429     \t     0.600     \n",
      "Accuracy : 0.45455 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:25<00:00, 24.06it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:18, 46.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 8 Loss : 1.18659\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.667     \t     1.000     \t     0.800     \n",
      "       1       \t     0.500     \t     0.500     \t     0.500     \n",
      "       2       \t     0.500     \t     0.500     \t     0.500     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     0.937     \t     0.882     \t     0.909     \n",
      "Accuracy : 0.79167 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 38.57it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:19, 25.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 8 Loss : 1.37139\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     1.000     \t     1.000     \n",
      "       1       \t     0.333     \t     1.000     \t     0.500     \n",
      "       2       \t     0.250     \t     0.500     \t     0.333     \n",
      "       3       \t     0.500     \t     0.750     \t     0.600     \n",
      "       4       \t     1.000     \t     0.571     \t     0.727     \n",
      "Accuracy : 0.63636 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:29<00:00, 23.42it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:19, 44.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 9 Loss : 1.17123\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.667     \t     1.000     \t     0.800     \n",
      "       1       \t     1.000     \t     1.000     \t     1.000     \n",
      "       2       \t     0.333     \t     0.500     \t     0.400     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.824     \t     0.903     \n",
      "Accuracy : 0.79167 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:22<00:00, 39.56it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:16, 25.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 9 Loss : 1.37021\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.333     \t     1.000     \t     0.500     \n",
      "       3       \t     0.286     \t     0.500     \t     0.364     \n",
      "       4       \t     1.000     \t     0.500     \t     0.667     \n",
      "Accuracy : 0.50000 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:45<00:00, 21.16it/s]\n",
      "  0%|▎                                                                                 | 3/877 [00:00<00:36, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 10 Loss : 1.15839\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.667     \t     1.000     \t     0.800     \n",
      "       1       \t     0.500     \t     1.000     \t     0.667     \n",
      "       2       \t     1.000     \t     0.500     \t     0.667     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.882     \t     0.938     \n",
      "Accuracy : 0.83333 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:32<00:00, 27.31it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:41, 21.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 10 Loss : 1.36914\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.500     \t     1.000     \t     0.667     \n",
      "       1       \t     0.500     \t     1.000     \t     0.667     \n",
      "       2       \t     0.333     \t     0.500     \t     0.400     \n",
      "       3       \t     0.500     \t     0.750     \t     0.600     \n",
      "       4       \t     1.000     \t     0.643     \t     0.783     \n",
      "Accuracy : 0.68182 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [03:24<00:00, 17.13it/s]\n",
      "  0%|                                                                                          | 0/877 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 11 Loss : 1.14843\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.667     \t     1.000     \t     0.800     \n",
      "       1       \t     0.500     \t     1.000     \t     0.667     \n",
      "       2       \t     1.000     \t     0.500     \t     0.667     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.882     \t     0.938     \n",
      "Accuracy : 0.83333 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:30<00:00, 28.98it/s]\n",
      "  0%|                                                                                 | 2/3506 [00:00<03:40, 15.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 11 Loss : 1.37238\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.333     \t     1.000     \t     0.500     \n",
      "       2       \t     0.200     \t     0.500     \t     0.286     \n",
      "       3       \t     0.500     \t     0.500     \t     0.500     \n",
      "       4       \t     0.900     \t     0.643     \t     0.750     \n",
      "Accuracy : 0.59091 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:48<00:00, 20.79it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:20, 42.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 12 Loss : 1.14006\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.667     \t     1.000     \t     0.800     \n",
      "       1       \t     0.500     \t     1.000     \t     0.667     \n",
      "       2       \t     0.500     \t     0.500     \t     0.500     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     1.000     \t     0.882     \t     0.938     \n",
      "Accuracy : 0.83333 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:25<00:00, 34.65it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:13, 26.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 12 Loss : 1.37327\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.250     \t     1.000     \t     0.400     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.500     \t     0.500     \t     0.500     \n",
      "       4       \t     0.900     \t     0.643     \t     0.750     \n",
      "Accuracy : 0.54545 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▌                                                                            | 111/3506 [00:04<02:16, 24.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-867392da66aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Loop\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-4962bee750c8>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1767\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1768\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1770\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2137\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2138\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2140\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   2059\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;34m'key'\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0mposition\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;34m'axis'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \"\"\"\n\u001b[1;32m-> 2061\u001b[1;33m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_axis\u001b[1;34m(self, axis)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_axis_name\u001b[1;34m(cls, axis)\u001b[0m\n\u001b[0;32m    409\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_ALIASES\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_NUMBERS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "pltloss = []\n",
    "pltacc = []\n",
    "\n",
    "pltloss_test = []\n",
    "pltacc_test = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_model = copy.deepcopy(net)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    print(\"Training Loop\")\n",
    "    for batch in tqdm(dloader):\n",
    "        metrics.reset()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        X, labels = batch[0].to(device), (batch[1] - 1).to(device)\n",
    "        pred = net(X)\n",
    "        loss = criterion(pred, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Training Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(losses) / len(losses)))\n",
    "    metrics.print_report()\n",
    "    pltloss.append(sum(losses) / len(losses))\n",
    "    pltacc.append(metrics.accuracy_score() * 100)\n",
    "    \n",
    "    test_losses = []\n",
    "    net.eval()\n",
    "    print(\"Validation Loop\")\n",
    "    for batch in tqdm(test_loader):\n",
    "        test_metrics.reset()\n",
    "\n",
    "        X, labels = batch[0].to(device), (batch[1] - 1).to(device)\n",
    "        pred = net(X)\n",
    "        loss = criterion(pred, labels)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "        test_metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Validation Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(test_losses) / len(test_losses)))\n",
    "    test_metrics.print_report()\n",
    "    pltloss_test.append(sum(test_losses) / len(test_losses))\n",
    "    pltacc_test.append(test_metrics.accuracy_score() * 100)\n",
    "    \n",
    "    if((test_metrics.accuracy_score() * 100) > best_val_acc):\n",
    "        best_val_acc = test_metrics.accuracy_score() * 100\n",
    "        best_model = copy.deepcopy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(pltloss))), pltloss)\n",
    "plt.plot(list(range(len(pltloss_test))), pltloss_test)\n",
    "\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting Accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(pltacc))), pltacc, )\n",
    "plt.plot(list(range(len(pltacc_test))), pltacc_test)\n",
    "\n",
    "plt.title(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python38164bittorchenvconda44d23debcd2b40f9b9e35123d075dc93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
