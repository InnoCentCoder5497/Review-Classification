{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification\n",
    "\n",
    "## Batching and Model Training\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Loading data\n",
    "import numpy as np\n",
    "import warnings \n",
    "import re # text matching\n",
    "from collections import Counter # for vocabulary\n",
    "from sklearn.model_selection import train_test_split # train test splits\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Processing\n",
    "\n",
    "We will first do all the necessary pre-processing before starting to create batches and training the model. All the steps are explained in the notebook named `Text Cleaning.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "# Drop unnecesary columns and duplicates\n",
    "new_data = data.drop_duplicates(subset=['UserId', 'ProfileName', 'Time', 'Text'])\n",
    "# Get useful columns\n",
    "useful_data = new_data[['Text', 'Score']]\n",
    "# Calculate length of each sentence without tokenizer\n",
    "useful_data['sudo_length'] = useful_data.Text.str.split().str.len()\n",
    "# Filter examples by length\n",
    "useful_data = useful_data[(useful_data.sudo_length > 20) & (useful_data.sudo_length < 100)]\n",
    "# Remove length column\n",
    "useful_data = useful_data.drop(['sudo_length'], axis = 1)\n",
    "# print 5 rows\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Creating vocabulary\n",
    "Now its time to tokenize and create our vocabulary. We use the `TextProcessor` class on data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.vocab_dict = dict({\"<unk>\" : 0, \"<pad>\" : 1})\n",
    "        self.counter = Counter()\n",
    "\n",
    "    def tokenize(self, sent):\n",
    "        if sent.endswith(\".\"):\n",
    "            sent = sent[:-1]\n",
    "        new_x = re.sub('<.*?>', ' ', sent)\n",
    "        new_x = re.sub('\\s\\s+',' ', new_x)\n",
    "        new_x = re.sub('\\W\\s', ' ', new_x)\n",
    "        new_x = re.sub('\\w\\W{2,}', ' ', new_x)\n",
    "        new_x = new_x.lower().split()\n",
    "        return new_x\n",
    "        \n",
    "    def processDataset(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        token_set = set(tokens)\n",
    "        self.counter.update(Counter(tokens))\n",
    "        return len(tokens)\n",
    "        \n",
    "    def build_vocab(self, num_most_common_to_use=10000):\n",
    "        words = self.counter.most_common(num_most_common_to_use)\n",
    "        for i in range(num_most_common_to_use - 2):\n",
    "            self.vocab_dict[words[i][0]] = len(self.vocab_dict)\n",
    "            \n",
    "    def tokenize_and_return_length(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        return len(tokens)\n",
    "            \n",
    "    def process(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        processed = []\n",
    "        for val in tokens:\n",
    "            processed.append(self.vocab_dict.get(val, self.vocab_dict[\"<unk>\"]))\n",
    "            \n",
    "        return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(useful_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run text processor to create vocabulary. Also create a new column denoting length of tokens for corresponding review. This will be used in creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296098</th>\n",
       "      <td>I have tried a lot of tortellini and this is o...</td>\n",
       "      <td>5</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239431</th>\n",
       "      <td>Not to say that I am a heavy martini drinker o...</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552535</th>\n",
       "      <td>I am a huge black licorice fan, however I don'...</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>I've tried a handful of other brands of French...</td>\n",
       "      <td>5</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21706</th>\n",
       "      <td>Our dog enjoys these better than any other har...</td>\n",
       "      <td>5</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "296098  I have tried a lot of tortellini and this is o...      5      59\n",
       "239431  Not to say that I am a heavy martini drinker o...      4      59\n",
       "552535  I am a huge black licorice fan, however I don'...      5      48\n",
       "2878    I've tried a handful of other brands of French...      5      37\n",
       "21706   Our dog enjoys these better than any other har...      5      43"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textprocessor = TextProcessor()\n",
    "train['length'] = train.Text.apply(textprocessor.processDataset)\n",
    "textprocessor.build_vocab()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269963</th>\n",
       "      <td>Its simply water. No aftertaste. I tested it o...</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560371</th>\n",
       "      <td>What can I say, my wife has almost used up one...</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503894</th>\n",
       "      <td>This tastes even better than the \"Butter Chick...</td>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127606</th>\n",
       "      <td>Lipton Family Size tea bags are a southern sta...</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67146</th>\n",
       "      <td>These tomatoes are the best I have found for c...</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "269963  Its simply water. No aftertaste. I tested it o...      5      64\n",
       "560371  What can I say, my wife has almost used up one...      5      29\n",
       "503894  This tastes even better than the \"Butter Chick...      5      33\n",
       "127606  Lipton Family Size tea bags are a southern sta...      5      48\n",
       "67146   These tomatoes are the best I have found for c...      5      36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['length'] = test.Text.apply(textprocessor.tokenize_and_return_length)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching and Data Loader creation\n",
    "We are going to use `PyTorch` for training an `LSTM Model` for classification of reviews. Before creating the model, we first need to create dataloader, so that we can conviniently pass our training and testing examples to our model.\n",
    "\n",
    "First we will create a *Custom PyTorch* dataset class which will preprocess our examples and convert them into a set of indices corresponging to vocabulary we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.data = df\n",
    "        self.data = self.data.sort_values(by='length')\n",
    "        self.tprocess = processor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row.Text\n",
    "        label = row.Score\n",
    "        \n",
    "        text = self.tprocess.process(text)\n",
    "        \n",
    "        return (text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe that our dataset class sorted our dataframe by the length of each sentence. This allows us to create a batch with minmum padding, as we will see later when creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data : \n",
      "([66, 0, 84, 0], 5)\n"
     ]
    }
   ],
   "source": [
    "dataset = ReviewDataset(train, textprocessor)\n",
    "\n",
    "print(\"Sample Data : \")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataloader\n",
    "\n",
    "#### Import Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom batch formation class\n",
    "Since our dataset contains all the examples in sorted fashion, the batch we will get from our dataloader will have the largest length sentence at the end of the batch list. In the batch collator class, we will first create an array or size `(batch_size, seq_len)`, where seq_len will be equal to the length of last sentence recieved in batch.\n",
    "\n",
    "As all the examples are sorted, padding required within a batch will be minimum as nearly equal length examples will be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    def __init__(self, pad_token = 1):\n",
    "        self.pad = pad_token\n",
    "    def __call__(self, batch):\n",
    "        batch_size = len(batch)\n",
    "        seq_len = len(batch[-1][0])\n",
    "        formed = np.zeros((batch_size, seq_len), dtype = np.long) + self.pad\n",
    "        labels = []\n",
    "        for i in range(batch_size):\n",
    "            example = batch[i]\n",
    "            formed[i, :len(example[0])] = example[0]\n",
    "            labels.append(example[1])\n",
    "            \n",
    "        return torch.LongTensor(formed), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = MyCollator()\n",
    "dloader = DataLoader(dataset, batch_size=32, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples : \n",
      "tensor([[  66,    0,   84,    0,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [   0,  111,  378,   10,   96,  226,   47, 1401,   63,  102,  654,    9,\n",
      "            0,    1,    1,    1,    1,    1],\n",
      "        [   0,  238,  150, 2100,   47,   36,  211,   51,    3,  198,   53,  567,\n",
      "          257, 4796, 1624,    1,    1,    1],\n",
      "        [5262,    0, 3065,    0, 1654, 8301, 2514,    0,    2,  185,  517,    7,\n",
      "          768,  283,  201,    1,    1,    1],\n",
      "        [ 118,  245,    0, 5873,  289,  366, 6545, 7169,   85,    0,  100,    5,\n",
      "         3036,  207,    2, 1538,    1,    1],\n",
      "        [ 608,    2,   62,   17, 4980,   29,  837,    2, 5837,   26,  229, 3609,\n",
      "         3210,  129, 7900, 6453,    1,    1],\n",
      "        [   8,  164,    9,  729, 3236,   14,    6,   65,  594,   56,  232,  371,\n",
      "          172,    2, 6857, 4512,    1,    1],\n",
      "        [  37,    8, 4990,   29,  985,   39,   65,  590, 1184,   14,  166, 1334,\n",
      "           21,   26, 2677,  172, 7149,    1],\n",
      "        [   3,  309,   91,  108,   23,  744,    7, 1067,    0,   43,   21,   37,\n",
      "           85, 1515, 4296,   31,    0,    1],\n",
      "        [  28,    9,    0,    6,  109,   82,   55, 6946,   27,  108,    6,   87,\n",
      "            6,    9,   28,    0,   58,    1],\n",
      "        [   0,  233,   19,  111,   22,   73, 2515,   12,    2,  236,   47,  181,\n",
      "           63,  102,  654,    9,    0,    1],\n",
      "        [  58, 2319,   17,   35,  147,    5,   75, 1735,   17,   64,  812,   17,\n",
      "           64,  249,  118, 1014,   39,    1],\n",
      "        [5262,    0, 3065,   40,  306,  642,  307,  433,  392,  548, 2439, 2294,\n",
      "         5291, 1692,  201,   10,  165,    1],\n",
      "        [   3,   26,    8,   33,    4,    3,  116,    6,    0, 2124,    0, 2073,\n",
      "            0,    0,    0,    0,  793,    1],\n",
      "        [  23,   19,  903,  714,   13, 3991,    3,   37,   30,  312,    5,   29,\n",
      "         2526,   73,   32,  115, 5716,    1],\n",
      "        [   8, 2352,  319,  714,  729,  989,  725,    7,  974,   47,  207,    6,\n",
      "           80,    0, 7545, 2774,    0,    1],\n",
      "        [  64,   68,    0,  272,    5,  216,   25,    0, 5641,  308,  544,    0,\n",
      "           31, 3590,    7,   85,  399,    1],\n",
      "        [ 113,  127, 2472,   13,  406,  266,  225,  157,   31, 3073,  714,   17,\n",
      "         1023, 1735, 2732,    0,    0,    1],\n",
      "        [2273, 2128,   32, 6071,   97,    3,   15,  148,  393,   10,    8,  164,\n",
      "            4,   59,   38, 1268,    6,    1],\n",
      "        [  29, 1106,  141, 2020,  550, 2188, 3330, 2182,  449,   27,  346,    3,\n",
      "          626,    7,   71,   11,    8, 1224],\n",
      "        [   5,  740,   10,  206, 1755,  232, 2339,   10,    8,  937,  829, 2155,\n",
      "         2319,    2,   62,  652, 1323, 5249],\n",
      "        [ 216,  216,  749, 5161, 5161, 7385,   99,  165,  108, 4597,    0,  258,\n",
      "         5161, 4525, 2770,   27,  111, 1175],\n",
      "        [   6,   58,  248,    6,   58,  372,    6,   58,  372,    6,   58,  372,\n",
      "            6,   58,  372,    6,   58,  372],\n",
      "        [ 681,   18, 9238, 2718,  550,  329,   11,   77, 3680, 2454,  730,   66,\n",
      "           24,  990,   13,  478,  127,    3],\n",
      "        [   0, 1778, 8569, 3082,   59,    0,  169, 5834,   31,   28,    4,   31,\n",
      "            0,   28,    0,   10,    0,    0],\n",
      "        [5262,    0, 3065,    3,   37,    8,  212,  169,    2,   62,    4,   65,\n",
      "          290,  241,    3,   54,  145, 3582],\n",
      "        [5262,    0, 3065,   23,  233,   19,   27,   29, 1212,  107, 4277,    7,\n",
      "          269,  178,   29,   22,   58, 1663],\n",
      "        [  58,   28,   39,   14,  359, 2167,  221,   51,   21,   49,   63,    5,\n",
      "         4723, 1154,  476,    5,  124,    0],\n",
      "        [   0, 5112,    0,    0,   11,  624, 1052, 1609,   15,    7,   36,  253,\n",
      "           24, 7048,    7,  108,    8, 6614],\n",
      "        [   0,  783,   19,    2,   62,  242,  783,   24, 1999,   16,   19, 1610,\n",
      "           12,    0,  505, 2430, 1199,    0],\n",
      "        [   8,    9,  107,  506,  121,   40,   34,    2, 8159,    2,    0,  260,\n",
      "            2, 4052,   29,  749,   29, 1106],\n",
      "        [   3,    0,    8,  789,    3,   67,    6,    5,  176,   24,   13, 1040,\n",
      "         1024,    4,    7, 1494,  557, 1144]])\n",
      "Labels : \n",
      "tensor([5, 5, 5, 5, 5, 5, 4, 5, 1, 5, 5, 5, 5, 3, 5, 4, 1, 5, 1, 5, 5, 1, 5, 5,\n",
      "        5, 5, 5, 4, 1, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dloader))\n",
    "print(\"Examples : \")\n",
    "print(batch[0])\n",
    "print(\"Labels : \")\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating calss weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 : 2.16131\n",
      "Class 2 : 3.99900\n",
      "Class 3 : 2.94995\n",
      "Class 4 : 1.54757\n",
      "Class 5 : 0.30284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', sorted(train.Score.unique()), train.Score)\n",
    "for cat in sorted(train.Score.unique()):\n",
    "    print(\"Class {} : {:.5f}\".format(cat, weights[cat - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start creating our model for Classification!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python38164bittorchenvconda44d23debcd2b40f9b9e35123d075dc93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
