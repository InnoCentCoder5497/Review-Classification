{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification\n",
    "\n",
    "## Torchtext Processing and Bidirectional LSTM\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Loading data\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split # train test splits\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Processing\n",
    "\n",
    "We will first do all the necessary pre-processing before starting to create batches and training the model. All the steps are explained in the notebook named `Text Cleaning.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "# Drop unnecesary columns and duplicates\n",
    "new_data = data.drop_duplicates(subset=['UserId', 'ProfileName', 'Time', 'Text'])\n",
    "# Get useful columns\n",
    "useful_data = new_data[['Text', 'Score']]\n",
    "# Calculate length of each sentence without tokenizer\n",
    "useful_data['sudo_length'] = useful_data.Text.str.split().str.len()\n",
    "# Filter examples by length\n",
    "useful_data = useful_data[(useful_data.sudo_length > 20) & (useful_data.sudo_length < 100)]\n",
    "# Remove length column\n",
    "useful_data = useful_data.drop(['sudo_length'], axis = 1)\n",
    "# print 5 rows\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(useful_data, test_size = 0.2)\n",
    "train.to_csv(\"./train_test_data/train.csv\", index=False)\n",
    "test.to_csv(\"./train_test_data/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.data import TabularDataset, Field, BucketIterator\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_en(sent):\n",
    "    sent = sent.lower()\n",
    "    return [item.text for item in tok.tokenizer(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'their', ',', 'why', 'do', \"n't\", 'u', 'have', 'a', 'seat', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"hello their, why don't u have a seat?\"\n",
    "tokenize_en(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT_FIELD = Field(sequential=True, tokenize=tokenize_en)\n",
    "LABEL_FIELD = Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)\n",
    "\n",
    "data_fields = [\n",
    "    ('Text', SENT_FIELD),\n",
    "    ('Score', LABEL_FIELD)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = TabularDataset.splits(\n",
    "    path='./train_test_data',\n",
    "    train='train.csv',\n",
    "    validation = 'test.csv',\n",
    "    format='csv',\n",
    "    skip_header=True,\n",
    "    fields=data_fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words : 101815\n"
     ]
    }
   ],
   "source": [
    "SENT_FIELD.build_vocab(train)\n",
    "SENT_FIELD.vocab.load_vectors('glove.6B.300d')\n",
    "\n",
    "print(\"Number of words : {}\".format(len(SENT_FIELD.vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "dev = 'cuda'\n",
    "\n",
    "train_iter, val_iter = BucketIterator.splits(\n",
    "    (train, val), \n",
    "    batch_sizes=(BATCH_SIZE, BATCH_SIZE), \n",
    "    sort_key=lambda x: len(x.Text), \n",
    "    shuffle=True, \n",
    "    sort_within_batch=True,\n",
    "    repeat=False,\n",
    "    device = dev\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationMetrics:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = list(range(num_classes))\n",
    "        self.epsilon = 1e-12\n",
    "        self.cmatrix = np.zeros((num_classes, num_classes), dtype = np.int64) + self.epsilon\n",
    "        \n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        \n",
    "    def update(self, pred, truth):\n",
    "        pred = pred.cpu()\n",
    "        truth = truth.cpu()\n",
    "        \n",
    "        _, idx = pred.topk(1)\n",
    "        truth = truth.view(-1, 1)\n",
    "        \n",
    "        self.total_examples += len(truth)\n",
    "        self.total_correct += sum(idx == truth).item()\n",
    "        \n",
    "        val = confusion_matrix(truth, idx, labels=self.classes)\n",
    "        \n",
    "        self.cmatrix = self.cmatrix + val\n",
    "        \n",
    "        \n",
    "    def precision_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[:, i]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def recall_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[i, :]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def scores(self, return_type = 'f1'):\n",
    "        pscores = self.precision_score()\n",
    "        rscores = self.recall_score()\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            if(pscores[i] == 0 and rscores[i] == 0):\n",
    "                scores[i] = 0\n",
    "            else:\n",
    "                scores[i] = 2 * ((pscores[i] * rscores[i]) / (pscores[i] + rscores[i])  + self.epsilon)\n",
    "            \n",
    "        if return_type == 'f1':\n",
    "            return scores\n",
    "        elif return_type == 'all':\n",
    "            all_scores = list(zip(pscores.values(), rscores.values(), scores.values()))\n",
    "            t = {}\n",
    "            for i in range(self.num_classes):\n",
    "                t[i] = all_scores[i]\n",
    "                \n",
    "            return t\n",
    "        else:\n",
    "            raise Exception(\"Invalid argument for return type\")\n",
    "            \n",
    "    def accuracy_score(self):\n",
    "        return self.total_correct / self.total_examples\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        self.cmatrix = np.zeros((self.num_classes, self.num_classes))\n",
    "            \n",
    "    def print_report(self):\n",
    "        all_scores = self.scores('all')\n",
    "        print(\"{:^15}\\t{:^15}\\t{:^15}\\t{:^15}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-score\"))\n",
    "        for c, values in all_scores.items():\n",
    "            print(\"{:^15}\\t{:^15.3f}\\t{:^15.3f}\\t{:^15.3f}\".format(c, values[0], values[1], values[2]))\n",
    "            \n",
    "        print(\"Accuracy : {:.5f} %\".format(self.accuracy_score()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalLstm(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(BiDirectionalLstm, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = nn.LSTM(embedding_dim, hidden_size, bidirectional = True, dropout = 0.2)\n",
    "        self.linear = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hstate = None):\n",
    "        if hstate is None:\n",
    "            hstate = self.init_hidden(self.hidden_size, x.shape[-1])\n",
    "            \n",
    "        cell_out, _ = self.cell(self.embedding(x), hstate)\n",
    "        \n",
    "        temp = torch.cat([cell_out[-1, :, :self.hidden_size], cell_out[0, :, self.hidden_size:]], axis = -1)\n",
    "        \n",
    "        out = self.linear(temp)\n",
    "        \n",
    "        return self.soft(out)\n",
    "            \n",
    "    def init_hidden(self, hidden_size, bs):\n",
    "        return (torch.zeros(2, bs, hidden_size, device=dev), torch.zeros(2, bs, hidden_size, device=dev))\n",
    "    \n",
    "    def load_embeddings(self, embeddings):\n",
    "        self.embedding.weight.data.copy_(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(SENT_FIELD.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "train = pd.read_csv(\"./train_test_data/train.csv\")\n",
    "weight_array = class_weight.compute_class_weight('balanced', sorted(train.Score.unique()), train.Score)\n",
    "del(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = BiDirectionalLstm(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
    "net.load_embeddings(SENT_FIELD.vocab.vectors)\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weight_array).to(dev))\n",
    "\n",
    "optimizer = opt.Adagrad(net.parameters())\n",
    "\n",
    "scheduler = opt.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "val_metrics = ClassificationMetrics(NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 7011/7011 [04:35<00:00, 25.46it/s]\n",
      "  1%|▍                                                                                | 9/1753 [00:00<00:19, 88.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 1 Loss : 1.56462\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.217     \t     0.437     \t     0.290     \n",
      "       1       \t     0.095     \t     0.011     \t     0.020     \n",
      "       2       \t     0.141     \t     0.007     \t     0.014     \n",
      "       3       \t     0.226     \t     0.005     \t     0.011     \n",
      "       4       \t     0.727     \t     0.882     \t     0.797     \n",
      "Accuracy : 0.62441 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1753/1753 [00:14<00:00, 121.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 1 Loss : 1.52646\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.213     \t     0.772     \t     0.334     \n",
      "       1       \t     0.117     \t     0.007     \t     0.013     \n",
      "       2       \t     0.127     \t     0.012     \t     0.023     \n",
      "       3       \t     0.216     \t     0.016     \t     0.030     \n",
      "       4       \t     0.808     \t     0.797     \t     0.803     \n",
      "Accuracy : 0.60052 %\n",
      "##\n",
      "New Best Accuracy : 60.05242\n",
      "##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/7011 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█                                                                               | 92/7011 [00:03<04:42, 24.49it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fc431558c5dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "N_EPOCH = 20\n",
    "\n",
    "tloss = []\n",
    "tacc = []\n",
    "vloss = []\n",
    "vacc = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_model = copy.deepcopy(net)\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    train_metrics.reset()\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for batch in tqdm(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        labels = batch.Score - 1\n",
    "        pred = net(batch.Text)\n",
    "\n",
    "        loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "\n",
    "        train_metrics.update(pred, labels)\n",
    "    \n",
    "    print(\"Training Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(losses) / len(losses)))\n",
    "    train_metrics.print_report()\n",
    "    tloss.append(sum(losses) / len(losses))\n",
    "    tacc.append(train_metrics.accuracy_score() * 100)\n",
    "    \n",
    "    val_metrics.reset()\n",
    "    val_losses = []\n",
    "    net.eval()\n",
    "    for batch in tqdm(val_iter):\n",
    "        labels = batch.Score - 1\n",
    "        pred = net(batch.Text)\n",
    "        loss = criterion(pred, labels)\n",
    "        val_losses.append(loss.item())\n",
    "        val_metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Validation Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(val_losses) / len(val_losses)))\n",
    "    val_metrics.print_report()\n",
    "    acc = val_metrics.accuracy_score() * 100\n",
    "    vloss.append(sum(val_losses) / len(val_losses))\n",
    "    vacc.append(acc)\n",
    "    \n",
    "    if(acc > best_val_acc):\n",
    "        print(\"##\\nNew Best Accuracy : {:.5f}\\n##\".format(acc))\n",
    "        best_val_acc = acc\n",
    "        best_model = copy.deepcopy(net)\n",
    "        torch.save(best_model.state_dict(), \"./models/network-val-acc-{:.2f}.pt\".format(best_val_acc))\n",
    "        print(\"Best model saved.\")\n",
    "        \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(tloss))), tloss, label=\"Training\")\n",
    "plt.plot(list(range(len(vloss))), vloss, label = \"Testing\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(\"Loss Curves\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(tacc))), tacc, label=\"Training\")\n",
    "plt.plot(list(range(len(vacc))), vacc, label = \"Testing\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = \"This food was good but i didn't like the place. Although, love the desert!\"\n",
    "\n",
    "pos_rev = SENT_FIELD.process([SENT_FIELD.preprocess(pos_sent)])\n",
    "\n",
    "net.eval()\n",
    "pred = net(pos_rev.to(dev))\n",
    "\n",
    "print(\"Review Rating as predicted : {}\".format(pred.topk(1)[1].item() + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = \"I just hated that food. Not recommended at all.\"\n",
    "\n",
    "pos_rev = SENT_FIELD.process([SENT_FIELD.preprocess(pos_sent)])\n",
    "\n",
    "net.eval()\n",
    "pred = net(pos_rev.to(dev))\n",
    "\n",
    "print(\"Review Rating as predicted : {}\".format(pred.topk(1)[1].item() + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = {}\n",
    "for z in range(len(SENT_FIELD.vocab)):\n",
    "    vocab_dict[SENT_FIELD.vocab.itos[z]] = z\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"./vocabdict.pkl\", \"wb\") as f:\n",
    "    pickle.dump([vocab_dict], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python38164bittorchenvconda44d23debcd2b40f9b9e35123d075dc93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
