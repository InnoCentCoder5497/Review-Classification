{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5j0azPkgNDoS"
   },
   "source": [
    "# Review Classification\n",
    "\n",
    "## Loading and Inference\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating necessary functions to load tokenizer and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "tok = spacy.load('en_core_web_sm')\n",
    "# loading vocabulary\n",
    "with open(\"./vocabdict.pkl\", \"rb\") as f:\n",
    "    vocab_dict = pickle.load(f)[0]\n",
    "# creating tokenizer function\n",
    "def tokenize_en(sent):\n",
    "    sent = sent.lower()\n",
    "    return [item.text for item in tok.tokenizer(sent)]\n",
    "# function to prepare sentence for inference\n",
    "def prepare_sentence(sent):\n",
    "    tokens = tokenize_en(pos_sent)\n",
    "    sent_idx = []\n",
    "\n",
    "    for item in tokens:\n",
    "        idx = vocab_dict.get(item, vocab_dict.get('<unk>'))\n",
    "        sent_idx.append([idx])\n",
    "        \n",
    "    return torch.LongTensor(sent_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiDirectionalLstm(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(BiDirectionalLstm, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = nn.LSTM(embedding_dim, hidden_size, bidirectional = True, dropout = 0.2)\n",
    "        self.linear = nn.Linear(hidden_size * 2, num_classes)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hstate = None):\n",
    "        if hstate is None:\n",
    "            hstate = self.init_hidden(self.hidden_size, x.shape[-1])\n",
    "            \n",
    "        cell_out, _ = self.cell(self.embedding(x), hstate)\n",
    "        \n",
    "        temp = torch.cat([cell_out[-1, :, :self.hidden_size], cell_out[0, :, self.hidden_size:]], axis = -1)\n",
    "        \n",
    "        out = self.linear(temp)\n",
    "        \n",
    "        return out\n",
    "            \n",
    "    def init_hidden(self, hidden_size, bs):\n",
    "        return (torch.zeros(2, bs, hidden_size, device=dev), torch.zeros(2, bs, hidden_size, device=dev))\n",
    "    \n",
    "    def load_embeddings(self, embeddings):\n",
    "        self.embedding.weight.data.copy_(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary Variables and Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_dict)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_SIZE = 128\n",
    "NUM_CLASSES = 5\n",
    "dev= 'cpu'\n",
    "\n",
    "net = BiDirectionalLstm(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
    "net.load_state_dict(torch.load(\"./models/network-val-acc-71.31.pt\"))\n",
    "\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "#### Prepare sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_sent = \"The place is good, nice vibe. Food was also great. Overall nice experience.\"\n",
    "\n",
    "psent = prepare_sentence(pos_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.softmax(net(psent), dim = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displaying Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1 Probability Percentage : 0.04%\n",
      "Rating 2 Probability Percentage : 0.51%\n",
      "Rating 3 Probability Percentage : 15.37%\n",
      "Rating 4 Probability Percentage : 63.12%\n",
      "Rating 5 Probability Percentage : 20.97%\n"
     ]
    }
   ],
   "source": [
    "for i, prob in enumerate(x[0]):\n",
    "    print(\"Rating {} Probability Percentage : {:.2f}%\".format(i + 1, prob.item() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python38164bittorchenvconda44d23debcd2b40f9b9e35123d075dc93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
