{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification\n",
    "\n",
    "## Batching and Model Training\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Loading data\n",
    "import numpy as np\n",
    "import warnings \n",
    "import re # text matching\n",
    "from collections import Counter # for vocabulary\n",
    "from sklearn.model_selection import train_test_split # train test splits\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Processing\n",
    "\n",
    "We will first do all the necessary pre-processing before starting to create batches and training the model. All the steps are explained in the notebook named `Text Cleaning.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "# Drop unnecesary columns and duplicates\n",
    "new_data = data.drop_duplicates(subset=['UserId', 'ProfileName', 'Time', 'Text'])\n",
    "# Get useful columns\n",
    "useful_data = new_data[['Text', 'Score']]\n",
    "# Calculate length of each sentence without tokenizer\n",
    "useful_data['sudo_length'] = useful_data.Text.str.split().str.len()\n",
    "# Filter examples by length\n",
    "useful_data = useful_data[(useful_data.sudo_length > 20) & (useful_data.sudo_length < 100)]\n",
    "# Remove length column\n",
    "useful_data = useful_data.drop(['sudo_length'], axis = 1)\n",
    "# print 5 rows\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Creating vocabulary\n",
    "Now its time to tokenize and create our vocabulary. We use the `TextProcessor` class on data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.vocab_dict = dict({\"<unk>\" : 0, \"<pad>\" : 1})\n",
    "        self.counter = Counter()\n",
    "\n",
    "    def tokenize(self, sent):\n",
    "        if sent.endswith(\".\"):\n",
    "            sent = sent[:-1]\n",
    "        new_x = re.sub('<.*?>', ' ', sent)\n",
    "        new_x = re.sub('\\s\\s+',' ', new_x)\n",
    "        new_x = re.sub('\\W\\s', ' ', new_x)\n",
    "        new_x = re.sub('\\w\\W{2,}', ' ', new_x)\n",
    "        new_x = new_x.lower().split()\n",
    "        return new_x\n",
    "        \n",
    "    def processDataset(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        token_set = set(tokens)\n",
    "        self.counter.update(Counter(tokens))\n",
    "        return len(tokens)\n",
    "        \n",
    "    def build_vocab(self, num_most_common_to_use=10000):\n",
    "        words = self.counter.most_common(num_most_common_to_use)\n",
    "        for i in range(num_most_common_to_use - 2):\n",
    "            self.vocab_dict[words[i][0]] = len(self.vocab_dict)\n",
    "            \n",
    "    def tokenize_and_return_length(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        return len(tokens)\n",
    "            \n",
    "    def process(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        processed = []\n",
    "        for val in tokens:\n",
    "            processed.append(self.vocab_dict.get(val, self.vocab_dict[\"<unk>\"]))\n",
    "            \n",
    "        return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(useful_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run text processor to create vocabulary. Also create a new column denoting length of tokens for corresponding review. This will be used in creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110566</th>\n",
       "      <td>A ship fast. Safely arrived. Starbucks Via Col...</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254509</th>\n",
       "      <td>This product arrived completely melted. Rather...</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60660</th>\n",
       "      <td>I tried this for the first time today, but I o...</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461159</th>\n",
       "      <td>Seriously, how can one think of making risotto...</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>great deal, especially for the price. Item arr...</td>\n",
       "      <td>5</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "110566  A ship fast. Safely arrived. Starbucks Via Col...      5      31\n",
       "254509  This product arrived completely melted. Rather...      3      40\n",
       "60660   I tried this for the first time today, but I o...      1      26\n",
       "461159  Seriously, how can one think of making risotto...      5      26\n",
       "3299    great deal, especially for the price. Item arr...      5      44"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textprocessor = TextProcessor()\n",
    "train['length'] = train.Text.apply(textprocessor.processDataset)\n",
    "textprocessor.build_vocab(40000)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335596</th>\n",
       "      <td>This tea isn't bad, it just made (to me) a wea...</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209603</th>\n",
       "      <td>Duke, the 17 year old wonderdog, gives these f...</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429106</th>\n",
       "      <td>My kids love this stuff and it is perfect for ...</td>\n",
       "      <td>5</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487595</th>\n",
       "      <td>There are other imitators out there, but none ...</td>\n",
       "      <td>5</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84721</th>\n",
       "      <td>This black type of cardamom is impossible to f...</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "335596  This tea isn't bad, it just made (to me) a wea...      2      68\n",
       "209603  Duke, the 17 year old wonderdog, gives these f...      4      90\n",
       "429106  My kids love this stuff and it is perfect for ...      5      54\n",
       "487595  There are other imitators out there, but none ...      5      74\n",
       "84721   This black type of cardamom is impossible to f...      5      56"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['length'] = test.Text.apply(textprocessor.tokenize_and_return_length)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching and Data Loader creation\n",
    "We are going to use `PyTorch` for training an `LSTM Model` for classification of reviews. Before creating the model, we first need to create dataloader, so that we can conviniently pass our training and testing examples to our model.\n",
    "\n",
    "First we will create a *Custom PyTorch* dataset class which will preprocess our examples and convert them into a set of indices corresponging to vocabulary we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.data = df\n",
    "        self.data = self.data.sort_values(by='length')\n",
    "        self.tprocess = processor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row.Text\n",
    "        label = row.Score\n",
    "        \n",
    "        text = self.tprocess.process(text)\n",
    "        \n",
    "        return (text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe that our dataset class sorted our dataframe by the length of each sentence. This allows us to create a batch with minmum padding, as we will see later when creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data : \n",
      "([66, 0, 81, 14844], 5)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = ReviewDataset(train, textprocessor)\n",
    "test_dataset = ReviewDataset(test, textprocessor)\n",
    "\n",
    "print(\"Sample Data : \")\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataloader\n",
    "\n",
    "#### Import Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom batch formation class\n",
    "Since our dataset contains all the examples in sorted fashion, the batch we will get from our dataloader will have the largest length sentence at the end of the batch list. In the batch collator class, we will first create an array or size `(batch_size, seq_len)`, where seq_len will be equal to the length of last sentence recieved in batch.\n",
    "\n",
    "As all the examples are sorted, padding required within a batch will be minimum as nearly equal length examples will be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    def __init__(self, pad_token = 1):\n",
    "        self.pad = pad_token\n",
    "    def __call__(self, batch):\n",
    "        batch_size = len(batch)\n",
    "        seq_len = len(batch[-1][0])\n",
    "        formed = np.zeros((batch_size, seq_len), dtype = np.long) + self.pad\n",
    "        labels = []\n",
    "        for i in range(batch_size):\n",
    "            example = batch[i]\n",
    "            formed[i, :len(example[0])] = example[0]\n",
    "            labels.append(example[1])\n",
    "            \n",
    "        return torch.LongTensor(formed), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "collator = MyCollator()\n",
    "dloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples : \n",
      "tensor([[   66,     0,    81,  ...,     1,     1,     1],\n",
      "        [  384,    56,   207,  ...,     1,     1,     1],\n",
      "        [    0,   111,   376,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [ 2077,    13,   294,  ..., 34658,   865, 34141],\n",
      "        [   29,   123,     7,  ...,   100,    64,  1648],\n",
      "        [    3,    15,  4826,  ...,   198,    10,   462]])\n",
      "Labels : \n",
      "tensor([5, 5, 5, 5, 4, 5, 5, 5, 5, 4, 5, 4, 1, 5, 5, 1, 5, 5, 5, 1, 5, 5, 2, 5,\n",
      "        5, 5, 1, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 5, 5, 5, 5,\n",
      "        5, 5, 5, 5, 5, 1, 5, 4, 5, 1, 4, 5, 4, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dloader))\n",
    "print(\"Examples : \")\n",
    "print(batch[0])\n",
    "print(\"Labels : \")\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating calss weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 : 2.16674\n",
      "Class 2 : 4.01726\n",
      "Class 3 : 2.93625\n",
      "Class 4 : 1.54014\n",
      "Class 5 : 0.30306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', sorted(train.Score.unique()), train.Score)\n",
    "for cat in sorted(train.Score.unique()):\n",
    "    print(\"Class {} : {:.5f}\".format(cat, weights[cat - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start creating our model for Classification!!\n",
    "\n",
    "### Import Pytorch and other modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x27f85f05b30>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import copy\n",
    "\n",
    "torch.manual_seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Base Model\n",
    "The base model is the simplest model we train. It consist of \n",
    "- **Embedding layer** : this layer transforms our indexes to 300-D vector that respresent a word.\n",
    "- **LSTM cell** : the core of our model, the LSTM cell\n",
    "- **Linear layer** : we take the last output of the lstm layer and use it to predict classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = nn.LSTM(embedding_dim, hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hstate = None):\n",
    "        if hstate is None:\n",
    "            hstate = self.init_hidden(self.hidden_size, x.shape[0])\n",
    "            \n",
    "        cell_out, _ = self.cell(self.embedding(x), hstate)\n",
    "        \n",
    "        out = self.linear(cell_out[:, -1, :])\n",
    "        \n",
    "        return self.soft(out)\n",
    "            \n",
    "    def init_hidden(self, hidden_size, bs):\n",
    "        return (torch.zeros(1, bs, hidden_size, device=device), torch.zeros(1, bs, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating evalutaion metrics\n",
    "The evaluation metrics for classification used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetrics:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = list(range(num_classes))\n",
    "        self.epsilon = 1e-12\n",
    "        self.cmatrix = np.zeros((num_classes, num_classes), dtype = np.int64) + self.epsilon\n",
    "        \n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        \n",
    "    def update(self, pred, truth):\n",
    "        pred = pred.cpu()\n",
    "        truth = truth.cpu()\n",
    "        \n",
    "        _, idx = pred.topk(1)\n",
    "        truth = truth.view(-1, 1)\n",
    "        \n",
    "        self.total_examples += len(truth)\n",
    "        self.total_correct += sum(idx == truth).item()\n",
    "        \n",
    "        val = confusion_matrix(truth, idx, labels=self.classes)\n",
    "        \n",
    "        self.cmatrix = self.cmatrix + val\n",
    "        \n",
    "        \n",
    "    def precision_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[:, i]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def recall_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[i, :]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def scores(self, return_type = 'f1'):\n",
    "        pscores = self.precision_score()\n",
    "        rscores = self.recall_score()\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            if(pscores[i] == 0 and rscores[i] == 0):\n",
    "                scores[i] = 0\n",
    "            else:\n",
    "                scores[i] = 2 * ((pscores[i] * rscores[i]) / (pscores[i] + rscores[i])  + self.epsilon)\n",
    "            \n",
    "        if return_type == 'f1':\n",
    "            return scores\n",
    "        elif return_type == 'all':\n",
    "            all_scores = list(zip(pscores.values(), rscores.values(), scores.values()))\n",
    "            t = {}\n",
    "            for i in range(self.num_classes):\n",
    "                t[i] = all_scores[i]\n",
    "                \n",
    "            return t\n",
    "        else:\n",
    "            raise Exception(\"Invalid argument for return type\")\n",
    "            \n",
    "    def accuracy_score(self):\n",
    "        return self.total_correct / self.total_examples\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        self.cmatrix = np.zeros((self.num_classes, self.num_classes))\n",
    "            \n",
    "    def print_report(self):\n",
    "        all_scores = self.scores('all')\n",
    "        print(\"{:^15}\\t{:^15}\\t{:^15}\\t{:^15}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-score\"))\n",
    "        for c, values in all_scores.items():\n",
    "            print(\"{:^15}\\t{:^15.3f}\\t{:^15.3f}\\t{:^15.3f}\".format(c, values[0], values[1], values[2]))\n",
    "            \n",
    "        print(\"Accuracy : {:.5f} %\".format(self.accuracy_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating necessary variables along with our BaseModel, loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel(\n",
      "  (embedding): Embedding(40000, 200)\n",
      "  (cell): LSTM(200, 128, batch_first=True)\n",
      "  (linear): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (soft): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(textprocessor.vocab_dict)\n",
    "HIDDEN_SIZE = 128\n",
    "EMB_DIM = 200\n",
    "NUM_CLASSES = 5\n",
    "device = 'cuda'\n",
    "\n",
    "net = BaseModel(VOCAB_SIZE, EMB_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
    "net = net.cuda()\n",
    "print(net)\n",
    "\n",
    "metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "test_metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).to(device))\n",
    "optim = opt.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/3506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:49<00:00, 20.68it/s]\n",
      "  0%|▎                                                                                 | 3/877 [00:00<00:39, 22.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 1 Loss : 1.46223\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.250     \t     0.667     \t     0.364     \n",
      "       4       \t     0.733     \t     0.647     \t     0.688     \n",
      "Accuracy : 0.54167 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:32<00:00, 26.84it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:08, 27.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 1 Loss : 1.40990\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.500     \t     0.667     \t     0.571     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.333     \t     1.000     \t     0.500     \n",
      "       3       \t     0.375     \t     0.750     \t     0.500     \n",
      "       4       \t     1.000     \t     0.385     \t     0.556     \n",
      "Accuracy : 0.50000 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:40<00:00, 21.91it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:20, 42.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 2 Loss : 1.38352\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.250     \t     0.667     \t     0.364     \n",
      "       4       \t     0.733     \t     0.647     \t     0.688     \n",
      "Accuracy : 0.54167 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:27<00:00, 32.44it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:32, 22.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 2 Loss : 1.39188\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.667     \t     0.800     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.250     \t     1.000     \t     0.400     \n",
      "       3       \t     0.400     \t     0.500     \t     0.444     \n",
      "       4       \t     0.909     \t     0.769     \t     0.833     \n",
      "Accuracy : 0.68182 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:51<00:00, 20.42it/s]\n",
      "  0%|▎                                                                                 | 4/877 [00:00<00:24, 36.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 3 Loss : 1.33896\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.273     \t     1.000     \t     0.429     \n",
      "       4       \t     1.000     \t     0.588     \t     0.741     \n",
      "Accuracy : 0.54167 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:27<00:00, 31.86it/s]\n",
      "  0%|                                                                                 | 2/3506 [00:00<03:13, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 3 Loss : 1.38042\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.667     \t     0.800     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.333     \t     1.000     \t     0.500     \n",
      "       3       \t     0.250     \t     0.250     \t     0.250     \n",
      "       4       \t     0.900     \t     0.692     \t     0.783     \n",
      "Accuracy : 0.59091 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:56<00:00, 19.90it/s]\n",
      "  0%|▎                                                                                 | 4/877 [00:00<00:25, 34.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 4 Loss : 1.29795\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.333     \t     0.667     \t     0.444     \n",
      "       4       \t     0.867     \t     0.765     \t     0.813     \n",
      "Accuracy : 0.62500 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:30<00:00, 28.53it/s]\n",
      "  0%|                                                                                 | 2/3506 [00:00<03:13, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 4 Loss : 1.39165\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.667     \t     0.800     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.200     \t     1.000     \t     0.333     \n",
      "       3       \t     0.400     \t     0.500     \t     0.444     \n",
      "       4       \t     0.889     \t     0.615     \t     0.727     \n",
      "Accuracy : 0.59091 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:46<00:00, 21.04it/s]\n",
      "  0%|▎                                                                                 | 4/877 [00:00<00:26, 33.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 5 Loss : 1.26367\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.000     \t     0.000     \t     0.000     \n",
      "       3       \t     0.286     \t     0.667     \t     0.400     \n",
      "       4       \t     0.929     \t     0.765     \t     0.839     \n",
      "Accuracy : 0.62500 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:27<00:00, 31.57it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:36, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 5 Loss : 1.37734\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.667     \t     0.800     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.167     \t     1.000     \t     0.286     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     0.818     \t     0.692     \t     0.750     \n",
      "Accuracy : 0.54545 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:59<00:00, 19.49it/s]\n",
      "  0%|▎                                                                                 | 3/877 [00:00<00:38, 22.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 6 Loss : 1.23329\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.500     \t     0.500     \t     0.500     \n",
      "       3       \t     0.286     \t     0.667     \t     0.400     \n",
      "       4       \t     1.000     \t     0.706     \t     0.828     \n",
      "Accuracy : 0.62500 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:30<00:00, 28.71it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:39, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 6 Loss : 1.37293\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.667     \t     0.800     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.167     \t     1.000     \t     0.286     \n",
      "       3       \t     0.000     \t     0.000     \t     0.000     \n",
      "       4       \t     0.750     \t     0.692     \t     0.720     \n",
      "Accuracy : 0.54545 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:57<00:00, 19.72it/s]\n",
      "  0%|▎                                                                                 | 4/877 [00:00<00:25, 34.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 7 Loss : 1.20802\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.500     \t     1.000     \t     0.667     \n",
      "       2       \t     0.333     \t     0.500     \t     0.400     \n",
      "       3       \t     0.167     \t     0.333     \t     0.222     \n",
      "       4       \t     1.000     \t     0.647     \t     0.786     \n",
      "Accuracy : 0.62500 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:27<00:00, 32.08it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:12, 26.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 7 Loss : 1.37434\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.333     \t     0.500     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.167     \t     1.000     \t     0.286     \n",
      "       3       \t     0.250     \t     0.250     \t     0.250     \n",
      "       4       \t     0.900     \t     0.692     \t     0.783     \n",
      "Accuracy : 0.54545 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:37<00:00, 22.22it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:17, 48.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 8 Loss : 1.18834\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.333     \t     0.500     \t     0.400     \n",
      "       2       \t     0.333     \t     0.500     \t     0.400     \n",
      "       3       \t     0.400     \t     0.667     \t     0.500     \n",
      "       4       \t     0.923     \t     0.706     \t     0.800     \n",
      "Accuracy : 0.66667 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:24<00:00, 35.99it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:09, 27.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 8 Loss : 1.37316\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.333     \t     0.500     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.200     \t     1.000     \t     0.333     \n",
      "       3       \t     0.250     \t     0.250     \t     0.250     \n",
      "       4       \t     0.900     \t     0.692     \t     0.783     \n",
      "Accuracy : 0.54545 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:36<00:00, 22.35it/s]\n",
      "  0%|▎                                                                                 | 4/877 [00:00<00:23, 37.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 9 Loss : 1.17396\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.250     \t     0.500     \t     0.333     \n",
      "       3       \t     0.182     \t     0.667     \t     0.286     \n",
      "       4       \t     1.000     \t     0.471     \t     0.640     \n",
      "Accuracy : 0.45833 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 877/877 [00:25<00:00, 34.99it/s]\n",
      "  0%|                                                                                 | 3/3506 [00:00<02:15, 25.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Run\n",
      "Epoch : 9 Loss : 1.37612\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     1.000     \t     0.333     \t     0.500     \n",
      "       1       \t     0.000     \t     0.000     \t     0.000     \n",
      "       2       \t     0.143     \t     1.000     \t     0.250     \n",
      "       3       \t     0.500     \t     0.500     \t     0.500     \n",
      "       4       \t     1.000     \t     0.692     \t     0.818     \n",
      "Accuracy : 0.59091 %\n",
      "Training Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3506/3506 [02:38<00:00, 22.15it/s]\n",
      "  1%|▍                                                                                 | 5/877 [00:00<00:18, 46.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Run\n",
      "Epoch : 10 Loss : 1.16154\n",
      "     Class     \t   Precision   \t    Recall     \t   F1-score    \n",
      "       0       \t     0.000     \t     0.000     \t     0.000     \n",
      "       1       \t     0.333     \t     0.500     \t     0.400     \n",
      "       2       \t     0.200     \t     0.500     \t     0.286     \n",
      "       3       \t     0.500     \t     0.667     \t     0.571     \n",
      "       4       \t     1.000     \t     0.647     \t     0.786     \n",
      "Accuracy : 0.62500 %\n",
      "Validation Loop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|██████████████████████████████████████▋                                         | 424/877 [00:11<00:15, 28.58it/s]"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "pltloss = []\n",
    "pltacc = []\n",
    "\n",
    "pltloss_test = []\n",
    "pltacc_test = []\n",
    "\n",
    "best_val_acc = 0\n",
    "best_model = copy.deepcopy(net)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    print(\"Training Loop\")\n",
    "    for batch in tqdm(dloader):\n",
    "        metrics.reset()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        X, labels = batch[0].to(device), (batch[1] - 1).to(device)\n",
    "        pred = net(X)\n",
    "        loss = criterion(pred, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Training Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(losses) / len(losses)))\n",
    "    metrics.print_report()\n",
    "    pltloss.append(sum(losses) / len(losses))\n",
    "    pltacc.append(metrics.accuracy_score() * 100)\n",
    "    \n",
    "    test_losses = []\n",
    "    net.eval()\n",
    "    print(\"Validation Loop\")\n",
    "    for batch in tqdm(test_loader):\n",
    "        test_metrics.reset()\n",
    "\n",
    "        X, labels = batch[0].to(device), (batch[1] - 1).to(device)\n",
    "        pred = net(X)\n",
    "        loss = criterion(pred, labels)\n",
    "        test_losses.append(loss.item())\n",
    "        \n",
    "        test_metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Validation Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(test_losses) / len(test_losses)))\n",
    "    test_metrics.print_report()\n",
    "    pltloss_test.append(sum(test_losses) / len(test_losses))\n",
    "    pltacc_test.append(test_metrics.accuracy_score() * 100)\n",
    "    \n",
    "    if((test_metrics.accuracy_score() * 100) > best_val_acc):\n",
    "        best_val_acc = test_metrics.accuracy_score() * 100\n",
    "        best_model = copy.deepcopy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(pltloss))), pltloss)\n",
    "plt.plot(list(range(len(pltloss_test))), pltloss_test)\n",
    "\n",
    "plt.title(\"Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ploting Accuracy curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(len(pltacc))), pltacc, )\n",
    "plt.plot(list(range(len(pltacc_test))), pltacc_test)\n",
    "\n",
    "plt.title(\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python38164bittorchenvconda44d23debcd2b40f9b9e35123d075dc93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
