{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification\n",
    "\n",
    "## Batching and Model Training\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Loading data\n",
    "import numpy as np\n",
    "import warnings \n",
    "import re # text matching\n",
    "from collections import Counter # for vocabulary\n",
    "from sklearn.model_selection import train_test_split # train test splits\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Processing\n",
    "\n",
    "We will first do all the necessary pre-processing before starting to create batches and training the model. All the steps are explained in the notebook named `Text Cleaning.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Score\n",
       "0  I have bought several of the Vitality canned d...      5\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...      1\n",
       "2  This is a confection that has been around a fe...      4\n",
       "3  If you are looking for the secret ingredient i...      2\n",
       "4  Great taffy at a great price.  There was a wid...      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataset\n",
    "data = pd.read_csv(\"Reviews.csv\")\n",
    "# Drop unnecesary columns and duplicates\n",
    "new_data = data.drop_duplicates(subset=['UserId', 'ProfileName', 'Time', 'Text'])\n",
    "# Get useful columns\n",
    "useful_data = new_data[['Text', 'Score']]\n",
    "# Calculate length of each sentence without tokenizer\n",
    "useful_data['sudo_length'] = useful_data.Text.str.split().str.len()\n",
    "# Filter examples by length\n",
    "useful_data = useful_data[(useful_data.sudo_length > 20) & (useful_data.sudo_length < 100)]\n",
    "# Remove length column\n",
    "useful_data = useful_data.drop(['sudo_length'], axis = 1)\n",
    "# print 5 rows\n",
    "useful_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing and Creating vocabulary\n",
    "Now its time to tokenize and create our vocabulary. We use the `TextProcessor` class on data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor:\n",
    "    def __init__(self):\n",
    "        self.vocab_dict = dict({\"<unk>\" : 0, \"<pad>\" : 1})\n",
    "        self.counter = Counter()\n",
    "\n",
    "    def tokenize(self, sent):\n",
    "        if sent.endswith(\".\"):\n",
    "            sent = sent[:-1]\n",
    "        new_x = re.sub('<.*?>', ' ', sent)\n",
    "        new_x = re.sub('\\s\\s+',' ', new_x)\n",
    "        new_x = re.sub('\\W\\s', ' ', new_x)\n",
    "        new_x = re.sub('\\w\\W{2,}', ' ', new_x)\n",
    "        new_x = new_x.lower().split()\n",
    "        return new_x\n",
    "        \n",
    "    def processDataset(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        token_set = set(tokens)\n",
    "        self.counter.update(Counter(tokens))\n",
    "        return len(tokens)\n",
    "        \n",
    "    def build_vocab(self, num_most_common_to_use=10000):\n",
    "        words = self.counter.most_common(num_most_common_to_use)\n",
    "        for i in range(num_most_common_to_use - 2):\n",
    "            self.vocab_dict[words[i][0]] = len(self.vocab_dict)\n",
    "            \n",
    "    def tokenize_and_return_length(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        return len(tokens)\n",
    "            \n",
    "    def process(self, sent):\n",
    "        tokens = self.tokenize(sent)\n",
    "        processed = []\n",
    "        for val in tokens:\n",
    "            processed.append(self.vocab_dict.get(val, self.vocab_dict[\"<unk>\"]))\n",
    "            \n",
    "        return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(useful_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run text processor to create vocabulary. Also create a new column denoting length of tokens for corresponding review. This will be used in creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>429048</th>\n",
       "      <td>I should have bought Goji berries by themselve...</td>\n",
       "      <td>3</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46813</th>\n",
       "      <td>Bakery on Main has another hit on their hands ...</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120575</th>\n",
       "      <td>despite a lot of negative reviews, I still bou...</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48214</th>\n",
       "      <td>Love the taste. Dont know why this drink has s...</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191664</th>\n",
       "      <td>I was pleasantly surprised to see these were a...</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "429048  I should have bought Goji berries by themselve...      3      87\n",
       "46813   Bakery on Main has another hit on their hands ...      5      27\n",
       "120575  despite a lot of negative reviews, I still bou...      5      56\n",
       "48214   Love the taste. Dont know why this drink has s...      5      23\n",
       "191664  I was pleasantly surprised to see these were a...      5      78"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textprocessor = TextProcessor()\n",
    "train['length'] = train.Text.apply(textprocessor.processDataset)\n",
    "textprocessor.build_vocab()\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255342</th>\n",
       "      <td>Read the description carefully.  Made by Spang...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444742</th>\n",
       "      <td>This producy works !!! Period......They were h...</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541879</th>\n",
       "      <td>I really only wanted to purchase a few tins. U...</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508821</th>\n",
       "      <td>&lt;a href=\"http://www.amazon.com/gp/product/B000...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384133</th>\n",
       "      <td>I have been using all the whey low products fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score  length\n",
       "255342  Read the description carefully.  Made by Spang...      1      34\n",
       "444742  This producy works !!! Period......They were h...      5      23\n",
       "541879  I really only wanted to purchase a few tins. U...      4      92\n",
       "508821  <a href=\"http://www.amazon.com/gp/product/B000...      1      39\n",
       "384133  I have been using all the whey low products fo...      5      35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['length'] = test.Text.apply(textprocessor.tokenize_and_return_length)\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching and Data Loader creation\n",
    "We are going to use `PyTorch` for training an `LSTM Model` for classification of reviews. Before creating the model, we first need to create dataloader, so that we can conviniently pass our training and testing examples to our model.\n",
    "\n",
    "First we will create a *Custom PyTorch* dataset class which will preprocess our examples and convert them into a set of indices corresponging to vocabulary we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.data = df\n",
    "        self.data = self.data.sort_values(by='length')\n",
    "        self.tprocess = processor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        text = row.Text\n",
    "        label = row.Score\n",
    "        \n",
    "        text = self.tprocess.process(text)\n",
    "        \n",
    "        return (text, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can observe that our dataset class sorted our dataframe by the length of each sentence. This allows us to create a batch with minmum padding, as we will see later when creating batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Data : \n",
      "([67, 0, 82, 0], 5)\n"
     ]
    }
   ],
   "source": [
    "dataset = ReviewDataset(train, textprocessor)\n",
    "\n",
    "print(\"Sample Data : \")\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataloader\n",
    "\n",
    "#### Import Dataloader class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom batch formation class\n",
    "Since our dataset contains all the examples in sorted fashion, the batch we will get from our dataloader will have the largest length sentence at the end of the batch list. In the batch collator class, we will first create an array or size `(batch_size, seq_len)`, where seq_len will be equal to the length of last sentence recieved in batch.\n",
    "\n",
    "As all the examples are sorted, padding required within a batch will be minimum as nearly equal length examples will be sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollator(object):\n",
    "    def __init__(self, pad_token = 1):\n",
    "        self.pad = pad_token\n",
    "    def __call__(self, batch):\n",
    "        batch_size = len(batch)\n",
    "        seq_len = len(batch[-1][0])\n",
    "        formed = np.zeros((batch_size, seq_len), dtype = np.long) + self.pad\n",
    "        labels = []\n",
    "        for i in range(batch_size):\n",
    "            example = batch[i]\n",
    "            formed[i, :len(example[0])] = example[0]\n",
    "            labels.append(example[1])\n",
    "            \n",
    "        return torch.LongTensor(formed), torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "collator = MyCollator()\n",
    "dloader = DataLoader(dataset, batch_size=BATCH_SIZE, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples : \n",
      "tensor([[  67,    0,   82,    0,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [ 464,  785,   29,    4,  228,   91, 1938,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [ 383,   56,  204,   40,   28,    0,   48,   63,  102,    8, 1034,  741,\n",
      "            1,    1,    1,    1,    1,    1],\n",
      "        [   0,  111,  376,   10,   96,  225,   48, 1419,   63,  102,  666,    9,\n",
      "            0,    1,    1,    1,    1,    1],\n",
      "        [5215,    0, 3099,    0, 1665, 8146, 2477,    0,    2,  185,  519,    7,\n",
      "          778,  282,  197,    1,    1,    1],\n",
      "        [   3,   26,    6,   31,   68,  712,   77,  149,    3,    0,   26,    7,\n",
      "           95,   60,  843,    1,    1,    1],\n",
      "        [   0,  235,  152, 2126,   48,   36,  213,   51,    3,  199,   53,  572,\n",
      "          257, 4901, 1674,    1,    1,    1],\n",
      "        [   0,  266,  243,   12,  142,  716,    4,   31,  364,   54,  181,   63,\n",
      "           46,   30, 1084,    1,    1,    1],\n",
      "        [ 119,  246,    0, 5965,  288,  367, 6968, 7569,   85,    0,  100,    5,\n",
      "         2912,  207,    2, 1538,    1,    1],\n",
      "        [ 603,    2,   62,   17, 4594,   29,  843,    2, 6206,   26,  230, 3612,\n",
      "         3319,  130, 7883, 6680,    1,    1],\n",
      "        [1054,   11, 1156,    0,  231, 3399,  239,  231, 3399,  133,  299,  834,\n",
      "          128,  139,  282, 1553,    1,    1],\n",
      "        [   8,  163,    9,  727, 3438,   14,    6,   65,  600,   56,  231,  371,\n",
      "          172,    2, 7311, 4619,    1,    1],\n",
      "        [   8, 2246,  312,  712,  727, 1005,  719,    7,  969,   48,  207,    6,\n",
      "           81,    0, 7810, 2724,    0,    1],\n",
      "        [  23,   19,  908,  712,   13, 3825,    3,   37,   30,  306,    5,   29,\n",
      "         2491,   73,   32,  115, 5912,    1],\n",
      "        [  28,    9,    0,    6,  109,   84,   55, 6674,   27,  108,    6,   87,\n",
      "            6,    9,   28,    0,   58,    1],\n",
      "        [   3,   26,    8,   33,    4,    3,  116,    6,    0, 2191,    0, 2048,\n",
      "            0,    0,    0,    0,  814,    1],\n",
      "        [   0,  232,   19,  111,   22,   73, 2547,   12,    2,  237,   48,  181,\n",
      "           63,  102,  666,    9,    0,    1],\n",
      "        [   3,  314,   91,  108,   23,  729,    7, 1043,    0,   43,   21,   37,\n",
      "           85, 1492, 4269,   31,    0,    1],\n",
      "        [  58, 2263,   17,   35,  146,    5,   75, 1743,   17,   64,  820,   17,\n",
      "           64,  250,  119, 1000,   39,    1],\n",
      "        [5215,    0, 3099,   40,  304,  647,  298,  437,  391,  543, 2401, 2285,\n",
      "         5571, 1682,  197,   10,  165,    1],\n",
      "        [ 214,   20,    0,    0,   11,    2,  257, 4901,    0,   11,  214,   21,\n",
      "          132,   56,  334,  150, 1084,    1],\n",
      "        [2983,   54,   63,  102,   35,   26,    2,  222,  408,  184,  367, 2772,\n",
      "          379,   21,    3,  166,    6,    1],\n",
      "        [2323, 2173,   32, 6200,   97,    3,   15,  148,  394,   10,    8,  163,\n",
      "            4,   59,   38, 1287,    6,    1],\n",
      "        [ 113,  127, 2698,   13,  405,  265,  222,  157,   31, 3120,  712,   17,\n",
      "         1016, 1743, 2760,    0,    0,    1],\n",
      "        [  37,    8, 4966,   29,  978,   39,   65,  580, 1217,   14,  168, 1347,\n",
      "           21,   26, 2669,  172, 7528,    1],\n",
      "        [  64,   68,    0,  270,    5,  210,   25,    0, 5786,  313,  545,    0,\n",
      "           31, 3619,    7,   85,  401,    1],\n",
      "        [   2, 3168, 4627, 1322,  299, 9975,  596,   14,  135,   21, 3475,   24,\n",
      "            6,    4,    6,  573, 9975,  596],\n",
      "        [  58,   28,   39,   14,  356, 2148,  220,   51,   21,   49,   63,    5,\n",
      "         4729, 1150,  473,    5,  124,    0],\n",
      "        [  45,  226,    8,   12, 3316,    6,  600,   77,  391,  898,    7,  427,\n",
      "           46, 1440,    7, 1163,  623,  859],\n",
      "        [ 234,    3,   73,  168,   16,   89,  144,   52,   84, 7625,    8, 2047,\n",
      "           39,  255, 1245, 4177, 6672,  436],\n",
      "        [   6,   58,  247,    6,   58,  368,    6,   58,  368,    6,   58,  368,\n",
      "            6,   58,  368,    6,   58,  368],\n",
      "        [ 210,  210,  741, 4947, 4947, 6873,   98,  165,  108, 4450,    0,  256,\n",
      "         4947, 4600, 2700,   27,  111, 1185]])\n",
      "Labels : \n",
      "tensor([5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 4, 4, 5, 5, 3, 5, 1, 5, 5, 1, 5, 1, 5,\n",
      "        5, 1, 2, 4, 5, 5, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(dloader))\n",
    "print(\"Examples : \")\n",
    "print(batch[0])\n",
    "print(\"Labels : \")\n",
    "print(batch[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating calss weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1 : 2.16915\n",
      "Class 2 : 3.98303\n",
      "Class 3 : 2.95403\n",
      "Class 4 : 1.54162\n",
      "Class 5 : 0.30296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', sorted(train.Score.unique()), train.Score)\n",
    "for cat in sorted(train.Score.unique()):\n",
    "    print(\"Class {} : {:.5f}\".format(cat, weights[cat - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to start creating our model for Classification!!\n",
    "\n",
    "### Import Pytorch modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as opt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_classes):\n",
    "        super(BaseModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = nn.LSTM(embedding_dim, hidden_size, batch_first = True)\n",
    "        self.linear = nn.Linear(hidden_size, num_classes)\n",
    "        self.soft = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x, hstate = None):\n",
    "        if hstate is None:\n",
    "            hstate = self.init_hidden(self.hidden_size, x.shape[0])\n",
    "            \n",
    "        cell_out, _ = self.cell(self.embedding(x), hstate)\n",
    "        \n",
    "        out = self.linear(cell_out[:, -1, :])\n",
    "        \n",
    "        return self.soft(out)\n",
    "            \n",
    "    def init_hidden(self, hidden_size, bs):\n",
    "        return (torch.zeros(1, bs, hidden_size, device=device), torch.zeros(1, bs, hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating evalutaion metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationMetrics:\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.classes = list(range(num_classes))\n",
    "        self.epsilon = 1e-12\n",
    "        self.cmatrix = np.zeros((num_classes, num_classes), dtype = np.int64) + self.epsilon\n",
    "        \n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        \n",
    "    def update(self, pred, truth):\n",
    "        pred = pred.cpu()\n",
    "        truth = truth.cpu()\n",
    "        \n",
    "        _, idx = pred.topk(1)\n",
    "        truth = truth.view(-1, 1)\n",
    "        \n",
    "        self.total_examples += len(truth)\n",
    "        self.total_correct += sum(idx == truth).item()\n",
    "        \n",
    "        val = confusion_matrix(truth, idx, labels=self.classes)\n",
    "        \n",
    "        self.cmatrix = self.cmatrix + val\n",
    "        \n",
    "        \n",
    "    def precision_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[:, i]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def recall_score(self):\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            scores[i] = self.cmatrix[i, i] / (sum(self.cmatrix[i, :]) + self.epsilon)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def scores(self, return_type = 'f1'):\n",
    "        pscores = self.precision_score()\n",
    "        rscores = self.recall_score()\n",
    "        scores = {}\n",
    "        for i in range(self.num_classes):\n",
    "            if(pscores[i] == 0 and rscores[i] == 0):\n",
    "                scores[i] = 0\n",
    "            else:\n",
    "                scores[i] = 2 * ((pscores[i] * rscores[i]) / (pscores[i] + rscores[i])  + self.epsilon)\n",
    "            \n",
    "        if return_type == 'f1':\n",
    "            return scores\n",
    "        elif return_type == 'all':\n",
    "            all_scores = list(zip(pscores.values(), rscores.values(), scores.values()))\n",
    "            t = {}\n",
    "            for i in range(self.num_classes):\n",
    "                t[i] = all_scores[i]\n",
    "                \n",
    "            return t\n",
    "        else:\n",
    "            raise Exception(\"Invalid argument for return type\")\n",
    "            \n",
    "    def accuracy_score(self):\n",
    "        return self.total_correct / self.total_examples\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total_correct = 0\n",
    "        self.total_examples = 0\n",
    "        self.cmatrix = np.zeros((self.num_classes, self.num_classes))\n",
    "            \n",
    "    def print_report(self):\n",
    "        all_scores = self.scores('all')\n",
    "        print(\"{:^15}\\t{:^15}\\t{:^15}\\t{:^15}\".format(\"Class\", \"Precision\", \"Recall\", \"F1-score\"))\n",
    "        for c, values in all_scores.items():\n",
    "            print(\"{:^15}\\t{:^15.3f}\\t{:^15.3f}\\t{:^15.3f}\".format(c, values[0], values[1], values[2]))\n",
    "            \n",
    "        print(\"Accuracy : {:.5f} %\".format(self.accuracy_score()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating necessary variables along with our BaseModel, loss function and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModel(\n",
      "  (embedding): Embedding(10000, 20)\n",
      "  (cell): LSTM(20, 30, batch_first=True)\n",
      "  (linear): Linear(in_features=30, out_features=5, bias=True)\n",
      "  (soft): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "VOCAB_SIZE = len(textprocessor.vocab_dict)\n",
    "HIDDEN_SIZE = 30\n",
    "EMB_DIM = 20\n",
    "NUM_CLASSES = 5\n",
    "device = 'cuda'\n",
    "\n",
    "net = BaseModel(VOCAB_SIZE, EMB_DIM, HIDDEN_SIZE, NUM_CLASSES)\n",
    "net = net.cuda()\n",
    "print(net)\n",
    "\n",
    "metrics = ClassificationMetrics(NUM_CLASSES)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weights).to(device))\n",
    "optim = opt.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|███████████████████████████████████████████████████████████████████▋          | 3044/3506 [01:39<00:15, 30.66it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-8147bb5e970a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 20\n",
    "\n",
    "pltloss = []\n",
    "pltacc = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    losses = []\n",
    "    net.train()\n",
    "    for batch in tqdm(dloader):\n",
    "        metrics.reset()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        X, labels = batch[0].to(device), (batch[1] - 1).to(device)\n",
    "        pred = net(X)\n",
    "        loss = criterion(pred, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        metrics.update(pred, labels)\n",
    "        \n",
    "    print(\"Training Run\\nEpoch : {} Loss : {:.5f}\".format(epoch + 1, sum(losses) / len(losses)))\n",
    "    metrics.print_report()\n",
    "    pltloss.append(sum(losses) / len(losses))\n",
    "    pltacc.append(metrics.accuracy_score() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit ('torchenv': conda)",
   "language": "python",
   "name": "python38164bittorchenvconda44d23debcd2b40f9b9e35123d075dc93"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
